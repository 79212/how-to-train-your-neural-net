{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "X = df.iloc[:, 0:4]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = trainData(torch.FloatTensor(X_train), torch.LongTensor(y_train.values))\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainedModel(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(PreTrainedModel, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 6)\n",
    "        self.layer_2 = nn.Linear(6, 8)\n",
    "        self.layer_out = nn.Linear(8, num_class)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT_FEATURES = len(X.columns)\n",
    "NUM_OUTPUT_CLASSES = 3\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedModel(\n",
      "  (layer_1): Linear(in_features=4, out_features=6, bias=True)\n",
      "  (layer_2): Linear(in_features=6, out_features=8, bias=True)\n",
      "  (layer_out): Linear(in_features=8, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = PreTrainedModel(num_feature = NUM_INPUT_FEATURES, num_class=NUM_OUTPUT_CLASSES)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00: | Loss: 1.13740 | Acc: 0.34167\n",
      "Epoch 01: | Loss: 1.10503 | Acc: 0.45000\n",
      "Epoch 02: | Loss: 1.06221 | Acc: 0.33333\n",
      "Epoch 03: | Loss: 0.98183 | Acc: 0.40833\n",
      "Epoch 04: | Loss: 0.88134 | Acc: 0.58333\n",
      "Epoch 05: | Loss: 0.77200 | Acc: 0.65000\n",
      "Epoch 06: | Loss: 0.68214 | Acc: 0.74167\n",
      "Epoch 07: | Loss: 0.60828 | Acc: 0.83333\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        y_pred_probs = model(X_batch)\n",
    "        loss = criterion(y_pred_probs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        batch_acc = (y_pred == y_batch).sum().item()/BATCH_SIZE\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += batch_acc\n",
    "    \n",
    "    print(f'Epoch {e+0:02}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.5f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test_batch in test_loader:\n",
    "        y_pred_probs = model(X_test_batch)\n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        \n",
    "        y_pred_list.append(y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.20      0.20        10\n",
      "         1.0       0.20      0.25      0.22         8\n",
      "         2.0       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.27        30\n",
      "   macro avg       0.27      0.26      0.26        30\n",
      "weighted avg       0.28      0.27      0.27        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1.weight :  torch.Size([6, 4]) \n",
      " tensor([[-0.2648,  0.1227, -0.7883, -0.0803],\n",
      "        [-0.1095, -0.6869,  0.0119, -0.5226],\n",
      "        [-0.1791,  0.2791, -0.5246, -0.6669],\n",
      "        [-0.2769, -0.1220,  0.2103, -0.1768],\n",
      "        [ 0.4458,  0.5001,  0.2323,  0.6193],\n",
      "        [-0.4455,  0.7174, -0.3018, -0.7256]]) \n",
      "\n",
      "====================================================================================================\n",
      "layer_1.bias :  torch.Size([6]) \n",
      " tensor([ 0.3653,  0.2289,  0.4179, -0.4063, -0.2165,  0.1836]) \n",
      "\n",
      "====================================================================================================\n",
      "layer_2.weight :  torch.Size([8, 6]) \n",
      " tensor([[ 0.5686, -0.1121,  0.5220, -0.1004, -0.4658,  0.5302],\n",
      "        [ 0.3992, -0.2845,  0.7956, -0.2060, -0.0964,  0.5952],\n",
      "        [-0.4409, -0.6192, -0.3328, -0.1938, -0.4393, -0.1782],\n",
      "        [ 0.4532,  0.5382, -0.5189, -0.2133, -0.1340,  0.0403],\n",
      "        [ 0.0009, -0.3969,  0.1155,  0.0045,  0.0661, -0.2889],\n",
      "        [-0.1400,  0.0989, -0.1770, -0.0407,  0.4508, -0.0686],\n",
      "        [-0.0869, -0.2890, -0.1779,  0.3563, -0.1222, -0.2564],\n",
      "        [-0.1229, -0.2406,  0.0193, -0.0092, -0.3095,  0.0606]]) \n",
      "\n",
      "====================================================================================================\n",
      "layer_2.bias :  torch.Size([8]) \n",
      " tensor([-0.1901,  0.0160, -0.1898,  0.0178, -0.4674,  0.5481, -0.3391, -0.3913]) \n",
      "\n",
      "====================================================================================================\n",
      "layer_out.weight :  torch.Size([3, 8]) \n",
      " tensor([[ 0.5986,  0.4669, -0.0686, -0.3567,  0.1407, -0.3337, -0.1343,  0.0558],\n",
      "        [-0.2043, -0.4740,  0.2900,  0.2494,  0.2005,  0.1860, -0.2963, -0.1195],\n",
      "        [-0.1449, -0.2433, -0.2558,  0.0349,  0.1344,  0.4532,  0.1795,  0.0175]]) \n",
      "\n",
      "====================================================================================================\n",
      "layer_out.bias :  torch.Size([3]) \n",
      " tensor([-7.9513e-02,  2.3980e-01, -5.9304e-06]) \n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, \": \",  param.shape, \"\\n\", param.data, \"\\n\")\n",
    "        print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics - Exploring Dataloaders and Loss Functions \n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)\n",
    "\n",
    "This notebook takes you through Dataloaders and a few commonly used loss functions used in various deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9520172ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom **dataset** class is created using 3 main components. \n",
    "\n",
    "* `__init__` \n",
    "* `__len__`\n",
    "* `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__init__` : used to perform initializing operations such as reading data and preprocessing.  \n",
    "`__len__`: returns the size of the input data.    \n",
    "`__getitem__`: returns data (input and output) in batches.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **dataloader** is then used on this **dataset** class to read the data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(custom_dataset_object, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a basic PyTorch dataset and dataloader. Assume you had input and output data as - \n",
    "\n",
    "\n",
    "`X`: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10  \n",
    "\n",
    "`y`: 0, 0, 0, 1, 0, 1, 1, 0, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = [0, 0, 0, 1, 0, 1, 1, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the dataset class. We will return a tuple of (input, output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomDataset(torch.FloatTensor(X), torch.FloatTensor(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method `__len__()` and `__getitem__()`.  \n",
    "\n",
    "`__getitem__()` takes the index as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.), tensor(1.))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the 4th (on the 3rd index) element in our data.\n",
    "data.__getitem__(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialise our dataloader now. Here we specify the batch size and shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3., 6.]), tensor([0., 1.])]\n"
     ]
    }
   ],
   "source": [
    "data_loader_iter = iter(data_loader)\n",
    "print(next(data_loader_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., 10.]) tensor([0., 1.])\n",
      "tensor([4., 6.]) tensor([1., 1.])\n",
      "tensor([7., 5.]) tensor([1., 0.])\n",
      "tensor([9., 3.]) tensor([0., 0.])\n",
      "tensor([2., 8.]) tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i,j in data_loader:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the commonly used loss functions for different deep learning tasks.  \n",
    "\n",
    "* Regression:  \n",
    "\n",
    "    * Mean Absolute Error - `torch.nn.L1Loss()`\n",
    "    * Mean Squared Error - `torch.nn.MSELoss()`\n",
    "    \n",
    "* Classification:\n",
    "    * Binary Classification\n",
    "        * Binary Cross Entropy Loss - `torch.nn.BCELoss()`\n",
    "        * Binary Cross Entropy with Logits Loss - `torch.nn.BCEWithLogitsLoss()`\n",
    "    * Multi-Class Classification\n",
    "        * Negative Log Likelihood - `torch.nn.NLLLoss()`\n",
    "        * CrossEntropyLoss - `torch.nn.CrossEntropyLoss()`\n",
    "        \n",
    "Learn more about the loss functions from the official [PyTorch docs](https://pytorch.org/docs/stable/nn.html#loss-functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [4.5000, 5.6000, 6.7000]], requires_grad=True)\n",
      "\n",
      "Y Pred shape:  torch.Size([2, 3]) \n",
      "\n",
      "==================================================\n",
      "\n",
      "Y Train: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [7.8000, 8.9000, 9.1000]])\n",
      "\n",
      "Y Train shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.tensor([[1.2, 2.3, 3.4], [4.5, 5.6, 6.7]], requires_grad=True)\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "print(\"\\nY Pred shape: \", y_pred.shape, \"\\n\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "y_train = torch.tensor([[1.2, 2.3, 3.4], [7.8, 8.9, 9.1]])\n",
    "print(\"\\nY Train: \\n\", y_train)\n",
    "print(\"\\nY Train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error - `torch.nn.L1Loss()`\n",
    "\n",
    "The input and output have to be the same size and have the dtype float.\n",
    "\n",
    "**y_pred** = `(batch_size, *)`   \n",
    "\n",
    "**y_train** = `(batch_size, *)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [4.5000, 5.6000, 6.7000]], requires_grad=True)\n",
      "Y Train: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [7.8000, 8.9000, 9.1000]])\n",
      "MAE Loss\n",
      " tensor(1.5000, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "mae_loss = nn.L1Loss()\n",
    "\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "\n",
    "print(\"Y Train: \\n\", y_train)\n",
    "\n",
    "output = mae_loss(y_pred, y_train)\n",
    "print(\"MAE Loss\\n\", output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error - `torch.nn.MSELoss()`\n",
    "\n",
    "The input and output have to be the same size and have the dtype float.\n",
    "\n",
    "**y_pred** = `(batch_size, *)`   \n",
    "\n",
    "**y_train** = `(batch_size, *)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [4.5000, 5.6000, 6.7000]], requires_grad=True)\n",
      "Y Train: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [7.8000, 8.9000, 9.1000]])\n",
      "MSE Loss\n",
      " tensor(4.5900, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "\n",
    "print(\"Y Train: \\n\", y_train)\n",
    "\n",
    "output = mse_loss(y_pred, y_train)\n",
    "print(\"MSE Loss\\n\", output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification\n",
    "\n",
    "`y_train` has two classes - 0 and 1. We use this BCE loss function in the situation when the final output from the network is a single value (final dense layer is of size 1) that lies between 0 and 1.\n",
    "\n",
    "Binary classification can be reframed to use NLLLoss or Crossentropy loss if the output from the network is a tensor of length 2 (final dense layer is of size 2) where both values lie between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [7.8000, 8.9000, 9.1000]], requires_grad=True)\n",
      "\n",
      "Y Pred shape:  torch.Size([2, 3]) \n",
      "\n",
      "==================================================\n",
      "\n",
      "Y Train: \n",
      " tensor([[1, 0, 1],\n",
      "        [0, 0, 1]])\n",
      "\n",
      "Y Train shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.tensor([[1.2, 2.3, 3.4], [7.8, 8.9, 9.1]], requires_grad = True)\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "print(\"\\nY Pred shape: \", y_pred.shape, \"\\n\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "y_train = torch.tensor([[1, 0, 1], [0, 0, 1]])\n",
    "print(\"\\nY Train: \\n\", y_train)\n",
    "print(\"\\nY Train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Cross Entropy Loss - `torch.nn.BCELoss()`\n",
    "\n",
    "\n",
    "The input and output have to be the same size and have the dtype float.\n",
    "\n",
    "**y_pred** = `(batch_size, *)`, Float (Value should be passed through a Sigmoid function to have a value between 0 and 1)\n",
    "\n",
    "**y_train** = `(batch_size, *)`, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [7.8000, 8.9000, 9.1000]], requires_grad=True)\n",
      "\n",
      "Y Pred Sigmoid: \n",
      " tensor([[0.7685, 0.9089, 0.9677],\n",
      "        [0.9996, 0.9999, 0.9999]], grad_fn=<SigmoidBackward>)\n",
      "\n",
      "Y Train: \n",
      " tensor([[1., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "\n",
      "BCE Loss\n",
      " tensor(3.2321, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "y_pred_sigmoid = torch.sigmoid(y_pred)\n",
    "\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "\n",
    "print(\"\\nY Pred Sigmoid: \\n\", y_pred_sigmoid)\n",
    "\n",
    "print(\"\\nY Train: \\n\", y_train.float())\n",
    "\n",
    "output = bce_loss(y_pred_sigmoid, y_train.float())\n",
    "print(\"\\nBCE Loss\\n\", output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Cross Entropy with Logits Loss - `torch.nn.BCEWithLogitsLoss()`\n",
    "\n",
    "\n",
    "The input and output have to be the same size and have the dtype float. This class combines *Sigmoid* and *BCELoss* into a single class. This version is numerically more stable than using *Sigmoid* + *BCELoss* individually.\n",
    "\n",
    "**y_pred** = `(batch_size, *)`, Float\n",
    "\n",
    "**y_train** = `(batch_size, *)`, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [7.8000, 8.9000, 9.1000]], requires_grad=True)\n",
      "\n",
      "Y Train: \n",
      " tensor([[1., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "\n",
      "BCE Loss\n",
      " tensor(3.2321, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    }
   ],
   "source": [
    "bce_logits_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "\n",
    "print(\"\\nY Train: \\n\", y_train.float())\n",
    "\n",
    "output = bce_logits_loss(y_pred, y_train.float())\n",
    "print(\"\\nBCE Loss\\n\", output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification\n",
    "\n",
    "`y_train` has 4 classes - 0, 1, 2, and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [4.5000, 5.6000, 6.7000],\n",
      "        [7.8000, 8.9000, 9.1000]], requires_grad=True)\n",
      "\n",
      "Y Pred shape:  torch.Size([3, 3]) \n",
      "\n",
      "==================================================\n",
      "\n",
      "Y Train: \n",
      " tensor([0, 1, 2])\n",
      "\n",
      "Y Train shape:  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.tensor([[1.2, 2.3, 3.4], [4.5, 5.6, 6.7], [7.8, 8.9, 9.1]], requires_grad = True)\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "print(\"\\nY Pred shape: \", y_pred.shape, \"\\n\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "y_train = torch.tensor([0, 1, 2])\n",
    "print(\"\\nY Train: \\n\", y_train)\n",
    "print(\"\\nY Train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Log Likelihood - `torch.nn.NLLLoss()`\n",
    "\n",
    "\n",
    "**y_pred** = `(batch_size, num_classes)`, Float (Value should be passed log probabilities which are obtained using the log_softmax function. \n",
    "\n",
    "**y_train** = `(batch_size)`, Long (range of values = 0, num_classes-1). The classes must start from 0, 1, 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [4.5000, 5.6000, 6.7000],\n",
      "        [7.8000, 8.9000, 9.1000]], requires_grad=True)\n",
      "\n",
      "Y Pred LogSoftmax: \n",
      " tensor([[-2.5672, -1.4672, -0.3672],\n",
      "        [-2.5672, -1.4672, -0.3672],\n",
      "        [-2.0378, -0.9378, -0.7378]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "Y Train: \n",
      " tensor([0, 1, 2])\n",
      "\n",
      "NLL Loss\n",
      " tensor(1.5907, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "nll_loss = nn.NLLLoss()\n",
    "\n",
    "y_pred_logsoftmax = torch.log_softmax(y_pred, dim = 1)\n",
    "\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "\n",
    "print(\"\\nY Pred LogSoftmax: \\n\", y_pred_logsoftmax)\n",
    "\n",
    "print(\"\\nY Train: \\n\", y_train)\n",
    "\n",
    "output = nll_loss(y_pred_logsoftmax, y_train)\n",
    "print(\"\\nNLL Loss\\n\", output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  CrossEntropyLoss - `torch.nn.CrossEntropyLoss()`\n",
    "\n",
    "This class combines *LogSoftmax* and *NLLLoss* into a single class.\n",
    "\n",
    "**y_pred** = `(batch_size, num_classes)`, Float  \n",
    "**y_train** = `(batch_size)`, Long (range of values = 0, num_classes-1). The classes must start from 0, 1, 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Pred: \n",
      " tensor([[1.2000, 2.3000, 3.4000],\n",
      "        [4.5000, 5.6000, 6.7000],\n",
      "        [7.8000, 8.9000, 9.1000]], requires_grad=True)\n",
      "\n",
      "Y Train: \n",
      " tensor([0, 1, 2])\n",
      "\n",
      "NLL Loss\n",
      " tensor(1.5907, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Y Pred: \\n\", y_pred)\n",
    "\n",
    "print(\"\\nY Train: \\n\", y_train)\n",
    "\n",
    "output = ce_loss(y_pred, y_train)\n",
    "print(\"\\nNLL Loss\\n\", output)\n",
    "\n",
    "output.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

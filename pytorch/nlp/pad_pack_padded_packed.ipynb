{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Exploring Padding and Packing Sequences\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)\n",
    "\n",
    "This notebook takes you throught the basics of padding and packing with respect to RNNs in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe1440a7ed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and Packing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([11, 12, 23, 14, 15, 16]),\n",
       " tensor([17, 18, 19, 20]),\n",
       " tensor([ 7,  8,  9, 10]),\n",
       " tensor([1, 2, 3]),\n",
       " tensor([4, 5]),\n",
       " tensor([21, 22])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor([1, 2, 3])\n",
    "b = torch.LongTensor([4, 5])\n",
    "c = torch.LongTensor([7, 8, 9, 10])\n",
    "d = torch.LongTensor([11, 12, 23, 14, 15, 16])\n",
    "e = torch.LongTensor([17, 18, 19, 20])\n",
    "f = torch.LongTensor([21, 22])\n",
    "# X = [a, b, c, d, e, f]\n",
    "X = [d, e, c, a, b, f]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 23, 14, 15, 16],\n",
       "        [17, 18, 19, 20,  0,  0],\n",
       "        [ 7,  8,  9, 10,  0,  0],\n",
       "        [ 1,  2,  3,  0,  0,  0],\n",
       "        [ 4,  5,  0,  0,  0,  0],\n",
       "        [21, 22,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "X_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the list and batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([11, 17,  7,  1,  4, 21, 12, 18,  8,  2,  5, 22, 23, 19,  9,  3, 14, 20,\n",
       "        10, 15, 16]), batch_sizes=tensor([6, 6, 4, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_packed = pack_padded_sequence(X_padded, lengths=[6, 4, 4, 3, 2, 2], batch_first=True)\n",
    "X_packed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding packed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11, 12, 23, 14, 15, 16],\n",
       "         [17, 18, 19, 20,  0,  0],\n",
       "         [ 7,  8,  9, 10,  0,  0],\n",
       "         [ 1,  2,  3,  0,  0,  0],\n",
       "         [ 4,  5,  0,  0,  0,  0],\n",
       "         [21, 22,  0,  0,  0,  0]]), tensor([6, 4, 4, 3, 2, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(X_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Example #1 [Dataloader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([11, 12, 23, 14, 15, 16]),\n",
       " tensor([17, 18, 19, 20]),\n",
       " tensor([ 7,  8,  9, 10]),\n",
       " tensor([1, 2, 3]),\n",
       " tensor([4, 5]),\n",
       " tensor([21, 22])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData(X)\n",
    "\n",
    "# Collate function is required here to use tensors of different sizes here\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 0\n",
      "-------------------------------------------------- \n",
      "\n",
      "Original Batch:\n",
      "[tensor([11, 12, 23, 14, 15, 16]), tensor([17, 18, 19, 20])]\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[11, 12, 23, 14, 15, 16],\n",
      "        [17, 18, 19, 20,  0,  0]])\n",
      "\n",
      "Pack padded seq:\n",
      "PackedSequence(data=tensor([11, 17, 12, 18, 23, 19, 14, 20, 15, 16]), batch_sizes=tensor([2, 2, 2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "Pad packed seq:\n",
      "(tensor([[11, 12, 23, 14, 15, 16],\n",
      "        [17, 18, 19, 20,  0,  0]]), tensor([6, 4]))\n",
      "====================================================================================================\n",
      "Batch Number: 1\n",
      "-------------------------------------------------- \n",
      "\n",
      "Original Batch:\n",
      "[tensor([ 7,  8,  9, 10]), tensor([1, 2, 3])]\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[ 7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  0]])\n",
      "\n",
      "Pack padded seq:\n",
      "PackedSequence(data=tensor([ 7,  1,  8,  2,  9,  3, 10]), batch_sizes=tensor([2, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "Pad packed seq:\n",
      "(tensor([[ 7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  0]]), tensor([4, 3]))\n",
      "====================================================================================================\n",
      "Batch Number: 2\n",
      "-------------------------------------------------- \n",
      "\n",
      "Original Batch:\n",
      "[tensor([4, 5]), tensor([21, 22])]\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[ 4,  5],\n",
      "        [21, 22]])\n",
      "\n",
      "Pack padded seq:\n",
      "PackedSequence(data=tensor([ 4, 21,  5, 22]), batch_sizes=tensor([2, 2]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "Pad packed seq:\n",
      "(tensor([[ 4,  5],\n",
      "        [21, 22]]), tensor([2, 2]))\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    len_list = list(map(len, batch))\n",
    "    \n",
    "    padded_seq = pad_sequence(batch, batch_first=True)\n",
    "    packed_seq = pack_padded_sequence(padded_seq, lengths=len_list, batch_first=True)\n",
    "    padded_seq_1 = pad_packed_sequence(packed_seq, batch_first=True)\n",
    "    \n",
    "    print(f\"Batch Number: {i}\")\n",
    "    print(\"-\"* 50, \"\\n\")\n",
    "    print(\"Original Batch:\")\n",
    "    print(batch)\n",
    "    print(\"\\nPadded Batch:\")\n",
    "    print(padded_seq)\n",
    "    print(\"\\nPack padded seq:\")\n",
    "    print(packed_seq)\n",
    "    print(\"\\nPad packed seq:\")\n",
    "    print(padded_seq_1)\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Example #2 [Dataloader + RNN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([11, 12, 23, 14, 15, 16]),\n",
       " tensor([17, 18, 19, 20]),\n",
       " tensor([ 7,  8,  9, 10]),\n",
       " tensor([1, 2, 3]),\n",
       " tensor([4, 5]),\n",
       " tensor([21, 22])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData(X)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "EMBEDDING_SIZE = 5\n",
    "VOCAB_SIZE = 24 #numbers 1 to 23\n",
    "HIDDEN_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size):\n",
    "        super(ModelRNN, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.rnn = nn.GRU(input_size = embedding_size, hidden_size = hidden_size, batch_first = True)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        len_list = list(map(len, batch))\n",
    "        print(\"Original Batch:\")\n",
    "        print(batch)\n",
    "        print(\"\\nList of tensor lengths per batch\", len_list)\n",
    "        padded_batch = pad_sequence(batch, batch_first=True)\n",
    "        print(\"\\nPadded Batch:\")\n",
    "        print(padded_batch)\n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        print(\"\\nEmbeddings: \")\n",
    "        print(embeds)\n",
    "        pack_embeds = pack_padded_sequence(embeds, lengths=len_list, batch_first=True)\n",
    "        print(\"\\nPacked Embeddings:\")\n",
    "        print(pack_embeds)\n",
    "        print(\"\\nRNN Output\")\n",
    "        rnn_out, rnn_hidden = self.rnn(pack_embeds)\n",
    "        print(\"\\n RNN Out: \")\n",
    "        print(rnn_out)\n",
    "        print(\"\\nRNN Hidden:\")\n",
    "        print(rnn_hidden)\n",
    "        print(\"\\nPadded RNN Output:\")\n",
    "        padded_rnn_out = pad_packed_sequence(rnn_out, batch_first = True) \n",
    "        print(padded_rnn_out)\n",
    "        \n",
    "        return padded_rnn_out, rnn_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelRNN(\n",
       "  (word_embeddings): Embedding(24, 5)\n",
       "  (rnn): GRU(5, 2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn = ModelRNN(embedding_size=EMBEDDING_SIZE, vocab_size=VOCAB_SIZE, hidden_size=HIDDEN_SIZE)\n",
    "model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 0\n",
      "-------------------------------------------------- \n",
      "\n",
      "Original Batch:\n",
      "[tensor([11, 12, 23, 14, 15, 16]), tensor([17, 18, 19, 20])]\n",
      "\n",
      "List of tensor lengths per batch [6, 4]\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[11, 12, 23, 14, 15, 16],\n",
      "        [17, 18, 19, 20,  0,  0]])\n",
      "\n",
      "Embeddings: \n",
      "tensor([[[-1.1669, -0.4375, -2.1085,  1.1450, -0.3822],\n",
      "         [-0.3553,  0.7542,  0.6901, -0.1443, -0.5146],\n",
      "         [-0.9336, -0.1527, -0.5300,  1.4535, -1.5414],\n",
      "         [ 1.5496,  0.5989,  0.4675, -0.1439, -0.8120],\n",
      "         [-0.3866, -1.0370,  0.5920, -0.7557,  0.3917],\n",
      "         [ 0.5722,  0.3078, -0.1259, -0.9578,  1.7518]],\n",
      "\n",
      "        [[ 0.9796,  0.4105,  1.7675,  0.7569,  0.9862],\n",
      "         [-0.8253,  0.1633,  0.5013,  1.4206,  1.1542],\n",
      "         [-1.5366,  1.0571, -1.1047,  0.1274, -0.0189],\n",
      "         [-0.4073,  0.5317, -0.7420, -0.6375,  0.6794],\n",
      "         [ 0.8989, -1.3884, -0.1670,  0.2851, -0.6411],\n",
      "         [ 0.8989, -1.3884, -0.1670,  0.2851, -0.6411]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "\n",
      "Packed Embeddings:\n",
      "PackedSequence(data=tensor([[-1.1669, -0.4375, -2.1085,  1.1450, -0.3822],\n",
      "        [ 0.9796,  0.4105,  1.7675,  0.7569,  0.9862],\n",
      "        [-0.3553,  0.7542,  0.6901, -0.1443, -0.5146],\n",
      "        [-0.8253,  0.1633,  0.5013,  1.4206,  1.1542],\n",
      "        [-0.9336, -0.1527, -0.5300,  1.4535, -1.5414],\n",
      "        [-1.5366,  1.0571, -1.1047,  0.1274, -0.0189],\n",
      "        [ 1.5496,  0.5989,  0.4675, -0.1439, -0.8120],\n",
      "        [-0.4073,  0.5317, -0.7420, -0.6375,  0.6794],\n",
      "        [-0.3866, -1.0370,  0.5920, -0.7557,  0.3917],\n",
      "        [ 0.5722,  0.3078, -0.1259, -0.9578,  1.7518]],\n",
      "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([2, 2, 2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "RNN Output\n",
      "\n",
      " RNN Out: \n",
      "PackedSequence(data=tensor([[ 0.1413,  0.7064],\n",
      "        [-0.1018, -0.3069],\n",
      "        [-0.0707,  0.5794],\n",
      "        [-0.6590, -0.1677],\n",
      "        [ 0.1815,  0.8136],\n",
      "        [-0.7596,  0.1688],\n",
      "        [ 0.2518,  0.4418],\n",
      "        [-0.5942,  0.2519],\n",
      "        [ 0.1340,  0.1859],\n",
      "        [-0.1134,  0.0979]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 2, 2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "RNN Hidden:\n",
      "tensor([[[-0.1134,  0.0979],\n",
      "         [-0.5942,  0.2519]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Padded RNN Output:\n",
      "(tensor([[[ 0.1413,  0.7064],\n",
      "         [-0.0707,  0.5794],\n",
      "         [ 0.1815,  0.8136],\n",
      "         [ 0.2518,  0.4418],\n",
      "         [ 0.1340,  0.1859],\n",
      "         [-0.1134,  0.0979]],\n",
      "\n",
      "        [[-0.1018, -0.3069],\n",
      "         [-0.6590, -0.1677],\n",
      "         [-0.7596,  0.1688],\n",
      "         [-0.5942,  0.2519],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]]], grad_fn=<TransposeBackward0>), tensor([6, 4]))\n",
      "====================================================================================================\n",
      "Batch Number: 1\n",
      "-------------------------------------------------- \n",
      "\n",
      "Original Batch:\n",
      "[tensor([ 7,  8,  9, 10]), tensor([1, 2, 3])]\n",
      "\n",
      "List of tensor lengths per batch [4, 3]\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[ 7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  0]])\n",
      "\n",
      "Embeddings: \n",
      "tensor([[[-0.6619, -0.8285, -0.6057, -0.1354,  0.7471],\n",
      "         [ 1.6409, -1.0567, -0.2616, -0.2501,  0.5011],\n",
      "         [ 0.2600, -1.6370,  0.1577, -0.0145, -0.3839],\n",
      "         [-2.9662, -1.0606, -0.3090,  0.9343, -0.3821]],\n",
      "\n",
      "        [[-0.8937, -0.1764,  1.7502, -1.1597, -0.4602],\n",
      "         [ 0.7085,  1.0128,  0.2304,  1.0902, -0.9371],\n",
      "         [ 0.8649,  1.9264, -0.3300,  0.1984,  0.7821],\n",
      "         [ 0.8989, -1.3884, -0.1670,  0.2851, -0.6411]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "\n",
      "Packed Embeddings:\n",
      "PackedSequence(data=tensor([[-0.6619, -0.8285, -0.6057, -0.1354,  0.7471],\n",
      "        [-0.8937, -0.1764,  1.7502, -1.1597, -0.4602],\n",
      "        [ 1.6409, -1.0567, -0.2616, -0.2501,  0.5011],\n",
      "        [ 0.7085,  1.0128,  0.2304,  1.0902, -0.9371],\n",
      "        [ 0.2600, -1.6370,  0.1577, -0.0145, -0.3839],\n",
      "        [ 0.8649,  1.9264, -0.3300,  0.1984,  0.7821],\n",
      "        [-2.9662, -1.0606, -0.3090,  0.9343, -0.3821]],\n",
      "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([2, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "RNN Output\n",
      "\n",
      " RNN Out: \n",
      "PackedSequence(data=tensor([[-0.0678,  0.2967],\n",
      "        [-0.2083,  0.0312],\n",
      "        [ 0.1734, -0.1031],\n",
      "        [ 0.0626,  0.0065],\n",
      "        [ 0.3784, -0.1042],\n",
      "        [-0.1700,  0.0024],\n",
      "        [-0.5716,  0.8431]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "RNN Hidden:\n",
      "tensor([[[-0.5716,  0.8431],\n",
      "         [-0.1700,  0.0024]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Padded RNN Output:\n",
      "(tensor([[[-0.0678,  0.2967],\n",
      "         [ 0.1734, -0.1031],\n",
      "         [ 0.3784, -0.1042],\n",
      "         [-0.5716,  0.8431]],\n",
      "\n",
      "        [[-0.2083,  0.0312],\n",
      "         [ 0.0626,  0.0065],\n",
      "         [-0.1700,  0.0024],\n",
      "         [ 0.0000,  0.0000]]], grad_fn=<TransposeBackward0>), tensor([4, 3]))\n",
      "====================================================================================================\n",
      "Batch Number: 2\n",
      "-------------------------------------------------- \n",
      "\n",
      "Original Batch:\n",
      "[tensor([4, 5]), tensor([21, 22])]\n",
      "\n",
      "List of tensor lengths per batch [2, 2]\n",
      "\n",
      "Padded Batch:\n",
      "tensor([[ 4,  5],\n",
      "        [21, 22]])\n",
      "\n",
      "Embeddings: \n",
      "tensor([[[ 1.0391, -0.7245, -0.8489, -1.2169, -1.8157],\n",
      "         [-0.3452, -2.0615,  0.6741, -1.3233, -1.3598]],\n",
      "\n",
      "        [[-0.3947,  1.3272,  0.1106,  0.3374, -0.3201],\n",
      "         [ 0.5689,  0.1333,  1.7422,  0.5880,  0.2755]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "\n",
      "Packed Embeddings:\n",
      "PackedSequence(data=tensor([[ 1.0391, -0.7245, -0.8489, -1.2169, -1.8157],\n",
      "        [-0.3947,  1.3272,  0.1106,  0.3374, -0.3201],\n",
      "        [-0.3452, -2.0615,  0.6741, -1.3233, -1.3598],\n",
      "        [ 0.5689,  0.1333,  1.7422,  0.5880,  0.2755]],\n",
      "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([2, 2]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "RNN Output\n",
      "\n",
      " RNN Out: \n",
      "PackedSequence(data=tensor([[ 0.0425,  0.2441],\n",
      "        [-0.2831,  0.1972],\n",
      "        [ 0.1558,  0.2831],\n",
      "        [-0.0811, -0.2223]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 2]), sorted_indices=None, unsorted_indices=None)\n",
      "\n",
      "RNN Hidden:\n",
      "tensor([[[ 0.1558,  0.2831],\n",
      "         [-0.0811, -0.2223]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Padded RNN Output:\n",
      "(tensor([[[ 0.0425,  0.2441],\n",
      "         [ 0.1558,  0.2831]],\n",
      "\n",
      "        [[-0.2831,  0.1972],\n",
      "         [-0.0811, -0.2223]]], grad_fn=<TransposeBackward0>), tensor([2, 2]))\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    len_list = list(map(len, batch))\n",
    "    \n",
    "    print(f\"Batch Number: {i}\")\n",
    "    print(\"-\"* 50, \"\\n\")   \n",
    "    model_rnn(batch)\n",
    "    print(\"=\" * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

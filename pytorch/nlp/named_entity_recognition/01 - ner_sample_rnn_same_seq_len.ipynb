{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition - RNN Demo\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)\n",
    "\n",
    "This notebook takes you through the basics of Named Entity Recognition using RNNs in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition sample example with 2 sentences of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f33a4033170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"Ronaldo is from Portugal.\".split(), [\"PER\", \"O\", \"O\", \"LOC\"]),\n",
    "    (\"Rooney is from England.\".split(), [\"PER\", \"O\", \"O\", \"LOC\"])\n",
    "]\n",
    "\n",
    "sentence_list = [training_data[x][0] for x in range(len(training_data))]\n",
    "tag_list = [training_data[x][1] for x in range(len(training_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ronaldo', 'is', 'from', 'Portugal.'], ['Rooney', 'is', 'from', 'England.']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PER', 'O', 'O', 'LOC'], ['PER', 'O', 'O', 'LOC']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the input data by converting it into lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_list = []\n",
    "for sentence, tags in training_data:\n",
    "    clean_sentence = [x.lower().split('.')[0] for x in sentence]\n",
    "    data_clean_list += [(clean_sentence, tags)]\n",
    "\n",
    "    \n",
    "sentence_clean_list = [data_clean_list[x][0] for x in range(len(data_clean_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ronaldo', 'is', 'from', 'portugal'], ['rooney', 'is', 'from', 'england']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_clean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab for input words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word-vocablury: 6\n",
      "\n",
      "['ronaldo', 'is', 'portugal', 'from', 'rooney', 'england']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sentence in sentence_clean_list:\n",
    "    words += sentence\n",
    "words = list(set(words))\n",
    "print(f\"Size of word-vocablury: {len(words)}\\n\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary for input <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ronaldo': 0, 'is': 1, 'portugal': 2, 'from': 3, 'rooney': 4, 'england': 5}\n"
     ]
    }
   ],
   "source": [
    "word2idx = {word: i for i, word in enumerate(words)}\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab for output tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tag-vocab: 3\n",
      "\n",
      "['O', 'LOC', 'PER']\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in tag_list:\n",
    "    tags += tag\n",
    "tags = list(set(tags))\n",
    "print(f\"Size of tag-vocab: {len(tags)}\\n\")\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary for output <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'LOC': 1, 'PER': 2}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {word: i for i, word in enumerate(tags)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the words into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['ronaldo', 'is', 'from', 'portugal'], ['rooney', 'is', 'from', 'england']],\n",
       " [['PER', 'O', 'O', 'LOC'], ['PER', 'O', 'O', 'LOC']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_clean_list, tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 3, 2], [4, 1, 3, 5]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[word2idx[w] for w in s] for s in sentence_clean_list]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 0, 0, 1], [2, 0, 0, 1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [[tag2idx[t] for t in s] for s in tag_list]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input -> RNN -> Linear -> Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 10\n",
    "HIDDEN_SIZE = 20\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(torch.Tensor(X).to(torch.int64), torch.Tensor(y).to(torch.long))\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 4])\n",
      "torch.Size([1, 4]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUtagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size):\n",
    "        super(GRUtagger, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.gru = nn.GRU(input_size = embedding_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=target_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        gru_out, _ = self.gru(embeds)\n",
    "        linear_out = self.linear(gru_out)\n",
    "        y_out = F.log_softmax(linear_out, dim=1)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUtagger(\n",
      "  (word_embeddings): Embedding(6, 10)\n",
      "  (gru): GRU(10, 20, batch_first=True)\n",
      "  (linear): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRUtagger(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE, target_size=len(tag2idx))\n",
    "print(gru_model)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(gru_model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the GRU output from the model looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0, 1, 3, 2]])\n",
      "\n",
      "Output:\n",
      "tensor([[[-1.3501, -1.3673, -1.5080],\n",
      "         [-1.2519, -1.4159, -1.2836],\n",
      "         [-1.4130, -1.3701, -1.3147],\n",
      "         [-1.5540, -1.3927, -1.4564]]]) torch.Size([1, 4, 3])\n",
      "\n",
      "Output Indices:\n",
      "tensor([0, 0, 2, 1])\n",
      "\n",
      "Actual Output:\n",
      "tensor([[2, 0, 0, 1]]) torch.Size([1, 4])\n",
      "==================================================\n",
      "Input:\n",
      "tensor([[4, 1, 3, 5]])\n",
      "\n",
      "Output:\n",
      "tensor([[[-1.3398, -1.4564, -1.4748],\n",
      "         [-1.3094, -1.4155, -1.2893],\n",
      "         [-1.4956, -1.3380, -1.3252],\n",
      "         [-1.4106, -1.3404, -1.4697]]]) torch.Size([1, 4, 3])\n",
      "\n",
      "Output Indices:\n",
      "tensor([0, 2, 2, 1])\n",
      "\n",
      "Actual Output:\n",
      "tensor([[2, 0, 0, 1]]) torch.Size([1, 4])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        print(\"Input:\")\n",
    "        print(x_batch)\n",
    "        y_out = gru_model(x_batch)\n",
    "        _, y_out_tags = torch.max(y_out.squeeze(), dim = 1)\n",
    "        \n",
    "        print(\"\\nOutput:\")\n",
    "        print(y_out, y_out.shape)\n",
    "        \n",
    "        print(\"\\nOutput Indices:\")\n",
    "        print(y_out_tags)\n",
    "        \n",
    "\n",
    "        print(\"\\nActual Output:\")\n",
    "        print(y_batch, y_batch.shape)\n",
    "        \n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the GRU model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nn.NLLLoss()** expects input and target to be 2-dimensional and 1-dimensional respectively.\n",
    "\n",
    "So, we will reshape the tensors as follows:  \n",
    "* input tensor (y_pred) to a 2d tensor from a 3d tensor. So, from `[1, 4, 3]` to `[4, 3]`. \n",
    "* target tensor (y_batch) to a 1d tensor from a 2d tensor. So, from `[1, 4]` to `[4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Loss: 1.39782\n",
      "Epoch: 02 | Loss: 1.39584\n",
      "Epoch: 03 | Loss: 1.39386\n",
      "Epoch: 04 | Loss: 1.39189\n",
      "Epoch: 05 | Loss: 1.38993\n",
      "Epoch: 06 | Loss: 1.38798\n",
      "Epoch: 07 | Loss: 1.38603\n",
      "Epoch: 08 | Loss: 1.38409\n",
      "Epoch: 09 | Loss: 1.38216\n",
      "Epoch: 10 | Loss: 1.38023\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, EPOCH+1):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        gru_model.zero_grad()\n",
    "        \n",
    "        y_pred = gru_model(x_batch)\n",
    "        y_batch = y_batch.view(-1)\n",
    "        y_pred = y_pred.view(-1, len(tag2idx))\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {e+0:02} | Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMtagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size):\n",
    "        super(LSTMtagger, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=target_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        linear_out = self.linear(lstm_out)\n",
    "        y_out = F.log_softmax(linear_out, dim=1)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMtagger(\n",
      "  (word_embeddings): Embedding(6, 10)\n",
      "  (lstm): LSTM(10, 20, batch_first=True)\n",
      "  (linear): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTMtagger(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE, target_size=len(tag2idx))\n",
    "print(lstm_model)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(lstm_model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the LSTM output from the model looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0, 1, 3, 2]])\n",
      "\n",
      "Output:\n",
      "tensor([[[-1.4406, -1.4216, -1.3859],\n",
      "         [-1.3527, -1.3968, -1.3765],\n",
      "         [-1.3716, -1.3627, -1.3308],\n",
      "         [-1.3824, -1.3653, -1.4560]]]) torch.Size([1, 4, 3])\n",
      "\n",
      "Output Indices:\n",
      "tensor([2, 0, 2, 1])\n",
      "\n",
      "Actual Output:\n",
      "tensor([[2, 0, 0, 1]]) torch.Size([1, 4])\n",
      "==================================================\n",
      "Input:\n",
      "tensor([[4, 1, 3, 5]])\n",
      "\n",
      "Output:\n",
      "tensor([[[-1.3971, -1.3982, -1.3906],\n",
      "         [-1.3705, -1.4080, -1.3985],\n",
      "         [-1.4153, -1.3534, -1.3632],\n",
      "         [-1.3632, -1.3864, -1.3933]]]) torch.Size([1, 4, 3])\n",
      "\n",
      "Output Indices:\n",
      "tensor([2, 0, 1, 0])\n",
      "\n",
      "Actual Output:\n",
      "tensor([[2, 0, 0, 1]]) torch.Size([1, 4])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        print(\"Input:\")\n",
    "        print(x_batch)\n",
    "        y_out = lstm_model(x_batch)\n",
    "        _, y_out_tags = torch.max(y_out.squeeze(), dim = 1)\n",
    "        \n",
    "        print(\"\\nOutput:\")\n",
    "        print(y_out, y_out.shape)\n",
    "        \n",
    "        print(\"\\nOutput Indices:\")\n",
    "        print(y_out_tags)\n",
    "        \n",
    "        print(\"\\nActual Output:\")\n",
    "        print(y_batch, y_batch.shape)\n",
    "        \n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Loss: 1.37968\n",
      "Epoch: 02 | Loss: 1.37901\n",
      "Epoch: 03 | Loss: 1.37834\n",
      "Epoch: 04 | Loss: 1.37767\n",
      "Epoch: 05 | Loss: 1.37701\n",
      "Epoch: 06 | Loss: 1.37634\n",
      "Epoch: 07 | Loss: 1.37567\n",
      "Epoch: 08 | Loss: 1.37501\n",
      "Epoch: 09 | Loss: 1.37434\n",
      "Epoch: 10 | Loss: 1.37368\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, EPOCH+1):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        lstm_model.zero_grad()\n",
    "\n",
    "        y_pred = lstm_model(x_batch)\n",
    "        y_batch = y_batch.view(-1)\n",
    "        y_pred = y_pred.view(-1, len(tag2idx))\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {e+0:02} | Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKED LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for stacked LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedLSTMtagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size):\n",
    "        super(StackedLSTMtagger, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, hidden_size=hidden_size, batch_first = True, num_layers = 10)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=target_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        linear_out = self.linear(lstm_out)\n",
    "        y_out = F.log_softmax(linear_out, dim=1)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackedLSTMtagger(\n",
      "  (word_embeddings): Embedding(6, 10)\n",
      "  (lstm): LSTM(10, 20, num_layers=10, batch_first=True)\n",
      "  (linear): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "stacked_lstm_model = StackedLSTMtagger(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE, target_size=len(tag2idx))\n",
    "print(stacked_lstm_model)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(stacked_lstm_model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the Stacked-LSTM output from the model looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0, 1, 3, 2]])\n",
      "\n",
      "Output:\n",
      "tensor([[[-1.4104, -1.3916, -1.3739],\n",
      "         [-1.3869, -1.3862, -1.3844],\n",
      "         [-1.3762, -1.3842, -1.3914],\n",
      "         [-1.3721, -1.3831, -1.3957]]]) torch.Size([1, 4, 3])\n",
      "\n",
      "Output Indices:\n",
      "tensor([2, 2, 0, 0])\n",
      "\n",
      "Actual Output:\n",
      "tensor([[2, 0, 0, 1]]) torch.Size([1, 4])\n",
      "==================================================\n",
      "Input:\n",
      "tensor([[4, 1, 3, 5]])\n",
      "\n",
      "Output:\n",
      "tensor([[[-1.4104, -1.3916, -1.3739],\n",
      "         [-1.3869, -1.3862, -1.3844],\n",
      "         [-1.3762, -1.3842, -1.3914],\n",
      "         [-1.3721, -1.3831, -1.3957]]]) torch.Size([1, 4, 3])\n",
      "\n",
      "Output Indices:\n",
      "tensor([2, 2, 0, 0])\n",
      "\n",
      "Actual Output:\n",
      "tensor([[2, 0, 0, 1]]) torch.Size([1, 4])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        print(\"Input:\")\n",
    "        print(x_batch)\n",
    "        y_out = stacked_lstm_model(x_batch)\n",
    "        _, y_out_tags = torch.max(y_out.squeeze(), dim = 1)\n",
    "        \n",
    "        print(\"\\nOutput:\")\n",
    "        print(y_out, y_out.shape)\n",
    "        \n",
    "        print(\"\\nOutput Indices:\")\n",
    "        print(y_out_tags)\n",
    "\n",
    "        print(\"\\nActual Output:\")\n",
    "        print(y_batch, y_batch.shape)\n",
    "        \n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Stacked-LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Loss: 1.38000\n",
      "Epoch: 02 | Loss: 1.37992\n",
      "Epoch: 03 | Loss: 1.37984\n",
      "Epoch: 04 | Loss: 1.37976\n",
      "Epoch: 05 | Loss: 1.37968\n",
      "Epoch: 06 | Loss: 1.37960\n",
      "Epoch: 07 | Loss: 1.37952\n",
      "Epoch: 08 | Loss: 1.37944\n",
      "Epoch: 09 | Loss: 1.37935\n",
      "Epoch: 10 | Loss: 1.37927\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, EPOCH+1):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        stacked_lstm_model.zero_grad()\n",
    "        \n",
    "        y_pred = stacked_lstm_model(x_batch)\n",
    "        y_batch = y_batch.view(-1)\n",
    "        y_pred = y_pred.view(-1, len(tag2idx))\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {e+0:02} | Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

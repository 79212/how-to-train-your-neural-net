{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Binary Text Classification using CNN+RNN\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)  \n",
    "\n",
    "This notebook takes you through the implementation of binary text classification in the form of sentiment analysis on yelp reviews using CNN+RNN in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f50b23ccbf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0                           Wow... Loved this place.    1\n",
       "1                                 Crust is not good.    0\n",
       "2          Not tasty and the texture was just nasty.    0\n",
       "3  Stopped by during the late May bank holiday of...    1\n",
       "4  The selection on the menu was great and so wer...    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../data/nlp/text_classification/yelp_labelled.txt\", sep=\"\\t\", header=None, names=['text', 'tag'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[-df['text'].str.split().str.len().lt(6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [t for t in df['text'].to_list()]\n",
    "tag_list = [t for t in df['tag'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
       " 'The selection on the menu was great and so were the prices.',\n",
       " 'Now I am getting angry and I want my damn pho.',\n",
       " \"Honeslty it didn't taste THAT fresh.)\",\n",
       " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
       " 'The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.',\n",
       " 'I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!',\n",
       " 'I was disgusted because I was pretty sure that was human hair.',\n",
       " 'I was shocked because no signs indicate cash only.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "sentence_list = [s.lower() for s in sentence_list]\n",
    "\n",
    "# Remove non alphavets\n",
    "regex_remove_nonalphabets = re.compile('[^a-zA-Z]')\n",
    "sentence_list = [regex_remove_nonalphabets.sub(' ', s) for s in sentence_list]\n",
    "\n",
    "# Remove words with less than 2 letters\n",
    "regex_remove_shortwords = re.compile(r'\\b\\w{1,2}\\b')\n",
    "sentence_list = [regex_remove_shortwords.sub(\"\", s) for s in sentence_list]\n",
    "\n",
    "# Remove words that appear only once\n",
    "c = Counter(w for s in sentence_list for w in s.split())\n",
    "sentence_list = [' '.join(y for y in x.split() if c[y] > 1) for x in sentence_list]\n",
    "\n",
    "# Strip extra whitespaces\n",
    "sentence_list = [\" \".join(s.split()) for s in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not tasty and the texture was just nasty',\n",
       " 'stopped during the late may off recommendation and loved',\n",
       " 'the selection the menu was great and were the prices',\n",
       " 'now getting and want damn pho',\n",
       " 'didn taste that fresh',\n",
       " 'the potatoes were like and you could tell they had been made time being kept under',\n",
       " 'the cashier had care what ever what had say still ended being overpriced',\n",
       " 'tried the chicken with mmmm',\n",
       " 'was because was pretty sure that was human hair',\n",
       " 'was because only']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word-vocablury: 797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sentence in sentence_list:\n",
    "    for w in sentence.split():\n",
    "        words.append(w)\n",
    "    \n",
    "words = list(set(words))\n",
    "print(f\"Size of word-vocablury: {len(words)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tag-vocab: 2\n",
      "\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in tag_list:\n",
    "    tags.append(tag)\n",
    "tags = list(set(tags))\n",
    "print(f\"Size of tag-vocab: {len(tags)}\\n\")\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {word: i for i, word in enumerate(tags)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the input and output to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[674, 3, 148, 741, 98, 305, 751, 86],\n",
       " [382, 242, 741, 584, 158, 133, 366, 148, 651],\n",
       " [741, 413, 741, 784, 305, 406, 148, 697, 741, 47]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[word2idx[w] for w in s.split()] for s in sentence_list]\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [tag2idx[t] for t in tag_list]\n",
    "y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  540\n",
      "X_test size:  232\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train size: \", len(X_train))\n",
    "print(\"X_test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_SAMPLE = 2\n",
    "EMBEDDING_SIZE_SAMPLE = 5\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE_SAMPLE = 3\n",
    "STACKED_LAYERS_SAMPLE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = SampleData(X_train, y_train)\n",
    "sample_loader = DataLoader(sample_data, batch_size=BATCH_SIZE_SAMPLE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[674, 597, 432, 741], [408, 338, 280, 55, 74, 741, 148, 741, 59, 429, 666, 338, 406]] \n",
      "\n",
      " [0, 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tl = iter(sample_loader)\n",
    "\n",
    "i,j = map(list, zip(*next(tl)))\n",
    "\n",
    "print(i,\"\\n\\n\", j, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample CNN+RNN class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCnnRnnSample(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size, stacked_layers):\n",
    "        super(ModelCnnRnnSample, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=100, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=7, kernel_size=3, stride=1, padding = 1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.gru = nn.GRU(input_size = 7, hidden_size=hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=1)\n",
    "        \n",
    "    def forward(self, x_batch):        \n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        print(\"\\nPadded X_batch: \", padded_batch.size(), \"\\n\", padded_batch, \"\\n\")\n",
    "\n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        print(\"\\nEmbeddings: \", embeds.size(), \"\\n\", embeds, \"\\n\")\n",
    "    \n",
    "        embeds_t = embeds.transpose(1, 2)\n",
    "        print(\"\\nEmbeddings transposed for CNN: \", embeds_t.size(), \"\\n\", embeds_t, \"\\n\")\n",
    "\n",
    "        cnn1 = torch.relu(self.conv1(embeds_t))\n",
    "        cnn2 = torch.relu(self.conv2(cnn1))\n",
    "        print(\"\\nCNN output: \", cnn2.size(), \"\\n\", cnn2)\n",
    "        \n",
    "        maxpool1 = self.maxpool(cnn2)\n",
    "        print(\"\\nMaxpool output: \", maxpool1.size(), \"\\n\", maxpool1)\n",
    "        \n",
    "        gru_input = maxpool1.transpose(1, 2)\n",
    "        print(\"\\nRNN Input: \", gru_input.size(), \"\\n\", gru_input)\n",
    "        \n",
    "        _, gru_hidden = self.gru(gru_input)\n",
    "        print(\"\\nRNN Last Hidden: \", gru_hidden.size(), \"\\n\", gru_hidden)\n",
    "        \n",
    "        \n",
    "#         linear_in, _ = torch.max(gru_hidden, dim = 2)\n",
    "#         print(\"\\nLinear input: \", linear_in.size(), \"\\n\", linear_in)\n",
    "\n",
    "        linear_out = self.linear(gru_hidden)\n",
    "        print(\"\\nLinear Output: \", linear_out.size(), \"\\n\", linear_out)\n",
    "        \n",
    "        y_out = torch.sigmoid(linear_out)\n",
    "#         print(\"\\nSigmoid:\\n\", y_out)\n",
    "\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCnnRnnSample(\n",
      "  (word_embeddings): Embedding(797, 5)\n",
      "  (conv1): Conv1d(5, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(100, 7, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (gru): GRU(7, 3, batch_first=True)\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_rnn_model_sample = ModelCnnRnnSample(embedding_size=EMBEDDING_SIZE_SAMPLE, vocab_size=len(word2idx), hidden_size = HIDDEN_SIZE_SAMPLE, target_size=len(tag2idx), stacked_layers=STACKED_LAYERS_SAMPLE)\n",
    "print(cnn_rnn_model_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output.\n",
    "\n",
    "output = [batch size, sent len, hid dim]  \n",
    "hidden = [batch size, 1, hid dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: \n",
      "[tensor([674, 597, 432, 741]),\n",
      " tensor([408, 338, 280,  55,  74, 741, 148, 741,  59, 429, 666, 338, 406])]\n",
      "\n",
      "y batch: \n",
      "[tensor(0), tensor(1)]\n",
      "\n",
      "Padded X_batch:  torch.Size([2, 13]) \n",
      " tensor([[674, 597, 432, 741,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [408, 338, 280,  55,  74, 741, 148, 741,  59, 429, 666, 338, 406]]) \n",
      "\n",
      "\n",
      "Embeddings:  torch.Size([2, 13, 5]) \n",
      " tensor([[[ 1.2912,  0.3553, -0.5949,  0.7913,  0.2434],\n",
      "         [ 1.0208, -0.1065,  0.2071,  0.5192,  0.1796],\n",
      "         [-0.6696, -0.7714, -0.2665,  0.0449, -0.7013],\n",
      "         [-1.8827, -0.3300,  0.8413, -1.2723, -0.1413],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798]],\n",
      "\n",
      "        [[ 0.9820,  1.1343, -0.9107,  0.5313,  0.1559],\n",
      "         [ 0.1768,  0.4097,  0.6644,  0.4256,  0.5046],\n",
      "         [ 0.3325,  1.5443,  0.2619,  0.7211, -0.1297],\n",
      "         [-0.0334,  0.7193,  1.0644, -0.8336, -1.1929],\n",
      "         [-0.9965,  0.8073,  1.1739, -0.9398,  0.3861],\n",
      "         [-1.8827, -0.3300,  0.8413, -1.2723, -0.1413],\n",
      "         [ 0.8034,  1.1834,  0.0237,  1.1120, -0.9972],\n",
      "         [-1.8827, -0.3300,  0.8413, -1.2723, -0.1413],\n",
      "         [-0.4319,  1.1788,  0.6222,  0.7879,  1.3686],\n",
      "         [ 0.7687,  1.5591,  1.5513,  1.0585,  0.1894],\n",
      "         [ 0.6601, -0.6477, -1.1533, -0.7474, -0.4844],\n",
      "         [ 0.1768,  0.4097,  0.6644,  0.4256,  0.5046],\n",
      "         [-0.1164,  0.6052,  2.0862, -0.8240, -0.4076]]]) \n",
      "\n",
      "\n",
      "Embeddings transposed for CNN:  torch.Size([2, 5, 13]) \n",
      " tensor([[[ 1.2912,  1.0208, -0.6696, -1.8827, -0.6540, -0.6540, -0.6540,\n",
      "          -0.6540, -0.6540, -0.6540, -0.6540, -0.6540, -0.6540],\n",
      "         [ 0.3553, -0.1065, -0.7714, -0.3300, -1.6095, -1.6095, -1.6095,\n",
      "          -1.6095, -1.6095, -1.6095, -1.6095, -1.6095, -1.6095],\n",
      "         [-0.5949,  0.2071, -0.2665,  0.8413, -0.1002, -0.1002, -0.1002,\n",
      "          -0.1002, -0.1002, -0.1002, -0.1002, -0.1002, -0.1002],\n",
      "         [ 0.7913,  0.5192,  0.0449, -1.2723, -0.6092, -0.6092, -0.6092,\n",
      "          -0.6092, -0.6092, -0.6092, -0.6092, -0.6092, -0.6092],\n",
      "         [ 0.2434,  0.1796, -0.7013, -0.1413, -0.9798, -0.9798, -0.9798,\n",
      "          -0.9798, -0.9798, -0.9798, -0.9798, -0.9798, -0.9798]],\n",
      "\n",
      "        [[ 0.9820,  0.1768,  0.3325, -0.0334, -0.9965, -1.8827,  0.8034,\n",
      "          -1.8827, -0.4319,  0.7687,  0.6601,  0.1768, -0.1164],\n",
      "         [ 1.1343,  0.4097,  1.5443,  0.7193,  0.8073, -0.3300,  1.1834,\n",
      "          -0.3300,  1.1788,  1.5591, -0.6477,  0.4097,  0.6052],\n",
      "         [-0.9107,  0.6644,  0.2619,  1.0644,  1.1739,  0.8413,  0.0237,\n",
      "           0.8413,  0.6222,  1.5513, -1.1533,  0.6644,  2.0862],\n",
      "         [ 0.5313,  0.4256,  0.7211, -0.8336, -0.9398, -1.2723,  1.1120,\n",
      "          -1.2723,  0.7879,  1.0585, -0.7474,  0.4256, -0.8240],\n",
      "         [ 0.1559,  0.5046, -0.1297, -1.1929,  0.3861, -0.1413, -0.9972,\n",
      "          -0.1413,  1.3686,  0.1894, -0.4844,  0.5046, -0.4076]]]) \n",
      "\n",
      "\n",
      "CNN output:  torch.Size([2, 7, 13]) \n",
      " tensor([[[0.1121, 0.0973, 0.1916, 0.0000, 0.0242, 0.0000, 0.0990, 0.0990,\n",
      "          0.0990, 0.0990, 0.0990, 0.1537, 0.0000],\n",
      "         [0.0955, 0.1190, 0.2334, 0.0368, 0.0000, 0.0576, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0230, 0.0497, 0.0094, 0.0000, 0.0674, 0.0000, 0.1128, 0.1128,\n",
      "          0.1128, 0.1128, 0.1128, 0.0092, 0.0029],\n",
      "         [0.0000, 0.0000, 0.0884, 0.0911, 0.5759, 0.4766, 0.4976, 0.4976,\n",
      "          0.4976, 0.4976, 0.4976, 0.4960, 0.2179],\n",
      "         [0.1633, 0.2737, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0475, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0969],\n",
      "         [0.0193, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2071, 0.1939, 0.4099, 0.0000, 0.0845, 0.1573, 0.2415, 0.0000,\n",
      "          0.3221, 0.2414, 0.1976, 0.3292, 0.0130],\n",
      "         [0.0000, 0.0000, 0.0530, 0.0403, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1287, 0.1194, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0428, 0.0000, 0.0000, 0.0521],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2331, 0.1918, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0052],\n",
      "         [0.2779, 0.3168, 0.4593, 0.0940, 0.2102, 0.0000, 0.3212, 0.1701,\n",
      "          0.2847, 0.5854, 0.1647, 0.1039, 0.1113],\n",
      "         [0.0654, 0.0148, 0.0000, 0.0000, 0.0000, 0.0241, 0.0000, 0.0000,\n",
      "          0.1345, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1610, 0.0559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "\n",
      "Maxpool output:  torch.Size([2, 7, 4]) \n",
      " tensor([[[0.1916, 0.0242, 0.0990, 0.1537],\n",
      "         [0.2334, 0.0576, 0.0000, 0.0000],\n",
      "         [0.0497, 0.0674, 0.1128, 0.1128],\n",
      "         [0.0884, 0.5759, 0.4976, 0.4976],\n",
      "         [0.2737, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0475, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0193, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4099, 0.1573, 0.3221, 0.3292],\n",
      "         [0.0530, 0.0403, 0.0000, 0.1287],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0428],\n",
      "         [0.0000, 0.2331, 0.1918, 0.0000],\n",
      "         [0.4593, 0.2102, 0.3212, 0.5854],\n",
      "         [0.0654, 0.0241, 0.1345, 0.0000],\n",
      "         [0.1610, 0.0000, 0.0000, 0.0000]]])\n",
      "\n",
      "RNN Input:  torch.Size([2, 4, 7]) \n",
      " tensor([[[0.1916, 0.2334, 0.0497, 0.0884, 0.2737, 0.0475, 0.0193],\n",
      "         [0.0242, 0.0576, 0.0674, 0.5759, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0990, 0.0000, 0.1128, 0.4976, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1537, 0.0000, 0.1128, 0.4976, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4099, 0.0530, 0.0000, 0.0000, 0.4593, 0.0654, 0.1610],\n",
      "         [0.1573, 0.0403, 0.0000, 0.2331, 0.2102, 0.0241, 0.0000],\n",
      "         [0.3221, 0.0000, 0.0000, 0.1918, 0.3212, 0.1345, 0.0000],\n",
      "         [0.3292, 0.1287, 0.0428, 0.0000, 0.5854, 0.0000, 0.0000]]])\n",
      "\n",
      "RNN Last Hidden:  torch.Size([1, 2, 3]) \n",
      " tensor([[[ 0.4599,  0.0162, -0.3955],\n",
      "         [ 0.2444, -0.0167, -0.3505]]])\n",
      "\n",
      "Linear Output:  torch.Size([1, 2, 1]) \n",
      " tensor([[[-0.2747],\n",
      "         [-0.1988]]])\n",
      "\n",
      "Model Output:  torch.Size([1, 2, 1])\n",
      "tensor([[[0.4318],\n",
      "         [0.4505]]])\n",
      "\n",
      "Y Output Tag: \n",
      " tensor([[[0.],\n",
      "         [0.]]])\n",
      "\n",
      "Actual Output: \n",
      "[tensor(0), tensor(1)]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in sample_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i) for i in x_batch]\n",
    "        y_batch = [torch.tensor(i) for i in y_batch]\n",
    "        \n",
    "        \n",
    "        print(\"X batch: \")\n",
    "        pprint(x_batch)\n",
    "        print(\"\\ny batch: \")\n",
    "        pprint(y_batch)\n",
    "        \n",
    "        y_out = cnn_rnn_model_sample(x_batch)\n",
    "        print(\"\\nModel Output: \", y_out.size())\n",
    "        print(y_out)\n",
    "                        \n",
    "        y_out_tag = torch.round(y_out)\n",
    "        print(\"\\nY Output Tag: \\n\", y_out_tag)\n",
    "        \n",
    "        \n",
    "        print(\"\\nActual Output: \")\n",
    "        print(y_batch)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 512\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.005\n",
    "STACKED_LAYERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestData(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=1, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+RNN Model Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCnnRnn(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size, stacked_layers):\n",
    "        super(ModelCnnRnn, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=64, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding = 1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.gru = nn.GRU(input_size = 16, hidden_size=hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x_batch):        \n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        \n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        embeds_t = embeds.transpose(1, 2)\n",
    "        \n",
    "        cnn1 = self.relu(self.conv1(embeds_t))\n",
    "        cnn1 = self.dropout(cnn1)\n",
    "        cnn2 = self.relu(self.conv2(cnn1))\n",
    "        cnn2 = self.dropout(cnn2)\n",
    "        cnn3 = self.relu(self.conv3(cnn2))\n",
    "        cnn3 = self.dropout(cnn3)\n",
    "        \n",
    "        gru_input = cnn3.transpose(1, 2)\n",
    "        _, gru_hidden = self.gru(gru_input)\n",
    "        \n",
    "        linear_out = self.linear(gru_hidden)\n",
    "        \n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCnnRnn(\n",
      "  (word_embeddings): Embedding(797, 512)\n",
      "  (conv1): Conv1d(512, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (gru): GRU(16, 64, batch_first=True)\n",
      "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_rnn_model = ModelCnnRnn(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE, target_size=len(tag2idx), stacked_layers=STACKED_LAYERS)\n",
    "\n",
    "cnn_rnn_model.to(device)\n",
    "print(cnn_rnn_model)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer =  optim.Adam(cnn_rnn_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.693399717 | Acc: 54.0\n",
      "Epoch 002: | Loss: 0.691596887 | Acc: 64.0\n",
      "Epoch 003: | Loss: 0.690825199 | Acc: 54.0\n",
      "Epoch 004: | Loss: 0.682170871 | Acc: 64.0\n",
      "Epoch 005: | Loss: 0.678511017 | Acc: 50.0\n",
      "Epoch 006: | Loss: 0.663026319 | Acc: 54.0\n",
      "Epoch 007: | Loss: 0.645953964 | Acc: 57.0\n",
      "Epoch 008: | Loss: 0.596029194 | Acc: 54.0\n",
      "Epoch 009: | Loss: 0.464356652 | Acc: 86.0\n",
      "Epoch 010: | Loss: 0.338667913 | Acc: 93.0\n",
      "Epoch 011: | Loss: 0.229146009 | Acc: 96.0\n",
      "Epoch 012: | Loss: 0.276522907 | Acc: 89.0\n",
      "Epoch 013: | Loss: 0.225944416 | Acc: 93.0\n",
      "Epoch 014: | Loss: 0.156504884 | Acc: 89.0\n",
      "Epoch 015: | Loss: 0.142707937 | Acc: 96.0\n",
      "Epoch 016: | Loss: 0.168017417 | Acc: 93.0\n",
      "Epoch 017: | Loss: 0.122333537 | Acc: 96.0\n",
      "Epoch 018: | Loss: 0.107507899 | Acc: 96.0\n",
      "Epoch 019: | Loss: 0.072540649 | Acc: 96.0\n",
      "Epoch 020: | Loss: 0.056513863 | Acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "cnn_rnn_model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = cnn_rnn_model(x_batch)\n",
    "                \n",
    "        loss = criterion(y_pred.squeeze(), y_batch.float())\n",
    "        acc = binary_acc(y_pred.squeeze(), y_batch.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.9f} | Acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "        \n",
    "        y_pred = cnn_rnn_model(x_batch)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred_tag = torch.round(y_pred)\n",
    "\n",
    "        y_out_tags_list.append(y_pred_tag.squeeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = [a.squeeze().tolist() for a in y_out_tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79 38]\n",
      " [18 97]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       117\n",
      "           1       0.72      0.84      0.78       115\n",
      "\n",
      "    accuracy                           0.76       232\n",
      "   macro avg       0.77      0.76      0.76       232\n",
      "weighted avg       0.77      0.76      0.76       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence                                                                        : Sentiment      \n",
      "\n",
      "this place has lot but                                                          :   1.0\n",
      "\n",
      "believe that this place great stop for those with huge belly and for sushi      :   1.0\n",
      "\n",
      "guess maybe went off night but was                                              :   0.0\n",
      "\n",
      "the meat was pretty dry had the sliced and pulled pork                          :   0.0\n",
      "\n",
      "this place one star and has with the food                                       :   1.0\n",
      "\n",
      "service perfect and the family atmosphere nice see                              :   1.0\n",
      "\n",
      "had tea which was good                                                          :   1.0\n",
      "\n",
      "great food and great service clean and friendly setting                         :   1.0\n",
      "\n",
      "great time family dinner night                                                  :   1.0\n",
      "\n",
      "had fantastic service and were pleased the atmosphere                           :   1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{:80}: {:15}\\n'.format(\"Sentence\", \"Sentiment\"))\n",
    "for sentence, tag in zip(X_test[:10], y_out_tags_list[:10]):\n",
    "    s = \" \".join([idx2word[w] for w in sentence])\n",
    "    print('{:80}: {:5}\\n'.format(s, tag))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

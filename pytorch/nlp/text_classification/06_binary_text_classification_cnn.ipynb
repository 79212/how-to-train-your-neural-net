{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Binary Text Classification using CNNs\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)  \n",
    "\n",
    "This notebook takes you through the implementation of binary text classification in the form of sentiment analysis on yelp reviews using CNNs in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcad74deb50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0                           Wow... Loved this place.    1\n",
       "1                                 Crust is not good.    0\n",
       "2          Not tasty and the texture was just nasty.    0\n",
       "3  Stopped by during the late May bank holiday of...    1\n",
       "4  The selection on the menu was great and so wer...    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../data/nlp/text_classification/yelp_labelled.txt\", sep=\"\\t\", header=None, names=['text', 'tag'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[-df['text'].str.split().str.len().lt(6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [t for t in df['text'].to_list()]\n",
    "tag_list = [t for t in df['tag'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
       " 'The selection on the menu was great and so were the prices.',\n",
       " 'Now I am getting angry and I want my damn pho.',\n",
       " \"Honeslty it didn't taste THAT fresh.)\",\n",
       " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
       " 'The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.',\n",
       " 'I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!',\n",
       " 'I was disgusted because I was pretty sure that was human hair.',\n",
       " 'I was shocked because no signs indicate cash only.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "sentence_list = [s.lower() for s in sentence_list]\n",
    "\n",
    "# Remove non alphavets\n",
    "regex_remove_nonalphabets = re.compile('[^a-zA-Z]')\n",
    "sentence_list = [regex_remove_nonalphabets.sub(' ', s) for s in sentence_list]\n",
    "\n",
    "# Remove words with less than 2 letters\n",
    "regex_remove_shortwords = re.compile(r'\\b\\w{1,2}\\b')\n",
    "sentence_list = [regex_remove_shortwords.sub(\"\", s) for s in sentence_list]\n",
    "\n",
    "# Remove words that appear only once\n",
    "c = Counter(w for s in sentence_list for w in s.split())\n",
    "sentence_list = [' '.join(y for y in x.split() if c[y] > 1) for x in sentence_list]\n",
    "\n",
    "# Strip extra whitespaces\n",
    "sentence_list = [\" \".join(s.split()) for s in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not tasty and the texture was just nasty',\n",
       " 'stopped during the late may off recommendation and loved',\n",
       " 'the selection the menu was great and were the prices',\n",
       " 'now getting and want damn pho',\n",
       " 'didn taste that fresh',\n",
       " 'the potatoes were like and you could tell they had been made time being kept under',\n",
       " 'the cashier had care what ever what had say still ended being overpriced',\n",
       " 'tried the chicken with mmmm',\n",
       " 'was because was pretty sure that was human hair',\n",
       " 'was because only']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word-vocablury: 797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sentence in sentence_list:\n",
    "    for w in sentence.split():\n",
    "        words.append(w)\n",
    "    \n",
    "words = list(set(words))\n",
    "print(f\"Size of word-vocablury: {len(words)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tag-vocab: 2\n",
      "\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in tag_list:\n",
    "    tags.append(tag)\n",
    "tags = list(set(tags))\n",
    "print(f\"Size of tag-vocab: {len(tags)}\\n\")\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {word: i for i, word in enumerate(tags)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the input and output to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[717, 679, 759, 606, 499, 760, 704, 143],\n",
       " [457, 646, 606, 299, 183, 564, 537, 759, 402],\n",
       " [606, 273, 606, 640, 760, 664, 759, 209, 606, 201]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[word2idx[w] for w in s.split()] for s in sentence_list]\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [tag2idx[t] for t in tag_list]\n",
    "y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  540\n",
      "X_test size:  232\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train size: \", len(X_train))\n",
    "print(\"X_test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_SAMPLE = 2\n",
    "EMBEDDING_SIZE_SAMPLE = 5\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE_SAMPLE = 3\n",
    "STACKED_LAYERS_SAMPLE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = SampleData(X_train, y_train)\n",
    "sample_loader = DataLoader(sample_data, batch_size=BATCH_SIZE_SAMPLE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332, 38, 599], [606, 267, 374, 279, 444, 606, 447, 444, 614, 196, 73, 555, 384]] \n",
      "\n",
      " [1, 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tl = iter(sample_loader)\n",
    "\n",
    "i,j = map(list, zip(*next(tl)))\n",
    "\n",
    "print(i,\"\\n\\n\", j, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample CNN class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCNNSample(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, target_size, stacked_layers):\n",
    "        super(ModelCNNSample, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=100, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=10, kernel_size=3, stride=1, padding = 1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.linear = nn.Linear(in_features = 10, out_features=1)\n",
    "        \n",
    "    def forward(self, x_batch):        \n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        print(\"\\nPadded X_batch: \", padded_batch.size(), \"\\n\", padded_batch, \"\\n\")\n",
    "\n",
    "        \n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        print(\"\\nEmbeddings: \", embeds.size(), \"\\n\", embeds, \"\\n\")\n",
    "    \n",
    "        embeds_t = embeds.transpose(1, 2)\n",
    "        print(\"\\nEmbeddings transposed for CNN: \", embeds_t.size(), \"\\n\", embeds_t, \"\\n\")\n",
    "\n",
    "        cnn1 = torch.relu(self.conv1(embeds_t))\n",
    "        cnn2 = torch.relu(self.conv2(cnn1))\n",
    "        print(\"\\nCNN output: \", cnn2.size(), \"\\n\", cnn2)\n",
    "        \n",
    "        maxpool1 = self.maxpool(cnn2)\n",
    "        print(\"\\nMaxpool output: \", maxpool1.size(), \"\\n\", maxpool1)\n",
    "        \n",
    "        linear_in, _ = torch.max(maxpool1, dim = 2)\n",
    "        print(\"\\nLinear input: \", linear_in.size(), \"\\n\", linear_in)\n",
    "\n",
    "\n",
    "        linear_out = self.linear(linear_in)\n",
    "        print(\"\\nLinear Output:\\n\", linear_out)\n",
    "        \n",
    "        y_out = torch.sigmoid(linear_out)\n",
    "        print(\"\\nSigmoid:\\n\", y_out)\n",
    "\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCNNSample(\n",
      "  (word_embeddings): Embedding(797, 5)\n",
      "  (conv1): Conv1d(5, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(100, 10, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_model_sample = ModelCNNSample(embedding_size=EMBEDDING_SIZE_SAMPLE, vocab_size=len(word2idx), target_size=len(tag2idx), stacked_layers=STACKED_LAYERS_SAMPLE)\n",
    "print(cnn_model_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output.\n",
    "\n",
    "output = [batch size, sent len, hid dim]  \n",
    "hidden = [batch size, 1, hid dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: \n",
      "[tensor([332,  38, 599]),\n",
      " tensor([606, 267, 374, 279, 444, 606, 447, 444, 614, 196,  73, 555, 384])]\n",
      "\n",
      "y batch: \n",
      "[tensor(1), tensor(0)]\n",
      "\n",
      "Padded X_batch:  torch.Size([2, 13]) \n",
      " tensor([[332,  38, 599,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [606, 267, 374, 279, 444, 606, 447, 444, 614, 196,  73, 555, 384]]) \n",
      "\n",
      "\n",
      "Embeddings:  torch.Size([2, 13, 5]) \n",
      " tensor([[[-3.3652e-01,  6.4831e-01, -4.7121e-02, -2.5583e-01, -7.7055e-01],\n",
      "         [ 6.2233e-01, -4.4814e-01,  1.7837e+00, -1.9542e-01,  5.1492e-01],\n",
      "         [-7.1053e-01,  1.4931e+00, -5.4710e-01,  4.9138e-01,  9.1791e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01]],\n",
      "\n",
      "        [[ 1.8238e+00,  5.9008e-01, -2.4141e-01,  1.2141e+00,  4.9021e-01],\n",
      "         [ 4.4388e-01,  3.5746e-01, -6.3342e-01,  3.6410e-01, -7.9675e-01],\n",
      "         [ 1.7065e-02, -8.7682e-01, -2.5958e-01, -1.7663e+00,  8.8077e-01],\n",
      "         [ 2.9346e-01,  9.9939e-01, -1.1187e-01,  8.9935e-01,  4.4174e-01],\n",
      "         [ 2.6320e-01, -4.3018e-01, -1.0832e+00,  2.4101e+00,  3.4299e-02],\n",
      "         [ 1.8238e+00,  5.9008e-01, -2.4141e-01,  1.2141e+00,  4.9021e-01],\n",
      "         [ 6.1185e-02,  1.8545e+00,  8.6186e-01, -6.0697e-01, -5.7792e-01],\n",
      "         [ 2.6320e-01, -4.3018e-01, -1.0832e+00,  2.4101e+00,  3.4299e-02],\n",
      "         [-7.9513e-01,  2.4765e-01,  5.7734e-01, -6.7842e-01,  5.2806e-01],\n",
      "         [-1.2693e+00,  1.7838e+00,  3.2938e-01,  1.0812e+00,  1.4006e+00],\n",
      "         [ 1.1093e+00, -5.2757e-01,  8.4868e-02,  9.8202e-04, -1.3848e+00],\n",
      "         [-1.2847e+00,  1.9117e-01,  2.2908e-01,  3.9628e-01, -1.5484e+00],\n",
      "         [ 1.4066e+00, -7.4039e-01, -2.6428e-01,  1.7371e-01, -2.9756e-01]]]) \n",
      "\n",
      "\n",
      "Embeddings transposed for CNN:  torch.Size([2, 5, 13]) \n",
      " tensor([[[-3.3652e-01,  6.2233e-01, -7.1053e-01, -6.5398e-01, -6.5398e-01,\n",
      "          -6.5398e-01, -6.5398e-01, -6.5398e-01, -6.5398e-01, -6.5398e-01,\n",
      "          -6.5398e-01, -6.5398e-01, -6.5398e-01],\n",
      "         [ 6.4831e-01, -4.4814e-01,  1.4931e+00, -1.6095e+00, -1.6095e+00,\n",
      "          -1.6095e+00, -1.6095e+00, -1.6095e+00, -1.6095e+00, -1.6095e+00,\n",
      "          -1.6095e+00, -1.6095e+00, -1.6095e+00],\n",
      "         [-4.7121e-02,  1.7837e+00, -5.4710e-01, -1.0017e-01, -1.0017e-01,\n",
      "          -1.0017e-01, -1.0017e-01, -1.0017e-01, -1.0017e-01, -1.0017e-01,\n",
      "          -1.0017e-01, -1.0017e-01, -1.0017e-01],\n",
      "         [-2.5583e-01, -1.9542e-01,  4.9138e-01, -6.0919e-01, -6.0919e-01,\n",
      "          -6.0919e-01, -6.0919e-01, -6.0919e-01, -6.0919e-01, -6.0919e-01,\n",
      "          -6.0919e-01, -6.0919e-01, -6.0919e-01],\n",
      "         [-7.7055e-01,  5.1492e-01,  9.1791e-01, -9.7977e-01, -9.7977e-01,\n",
      "          -9.7977e-01, -9.7977e-01, -9.7977e-01, -9.7977e-01, -9.7977e-01,\n",
      "          -9.7977e-01, -9.7977e-01, -9.7977e-01]],\n",
      "\n",
      "        [[ 1.8238e+00,  4.4388e-01,  1.7065e-02,  2.9346e-01,  2.6320e-01,\n",
      "           1.8238e+00,  6.1185e-02,  2.6320e-01, -7.9513e-01, -1.2693e+00,\n",
      "           1.1093e+00, -1.2847e+00,  1.4066e+00],\n",
      "         [ 5.9008e-01,  3.5746e-01, -8.7682e-01,  9.9939e-01, -4.3018e-01,\n",
      "           5.9008e-01,  1.8545e+00, -4.3018e-01,  2.4765e-01,  1.7838e+00,\n",
      "          -5.2757e-01,  1.9117e-01, -7.4039e-01],\n",
      "         [-2.4141e-01, -6.3342e-01, -2.5958e-01, -1.1187e-01, -1.0832e+00,\n",
      "          -2.4141e-01,  8.6186e-01, -1.0832e+00,  5.7734e-01,  3.2938e-01,\n",
      "           8.4868e-02,  2.2908e-01, -2.6428e-01],\n",
      "         [ 1.2141e+00,  3.6410e-01, -1.7663e+00,  8.9935e-01,  2.4101e+00,\n",
      "           1.2141e+00, -6.0697e-01,  2.4101e+00, -6.7842e-01,  1.0812e+00,\n",
      "           9.8202e-04,  3.9628e-01,  1.7371e-01],\n",
      "         [ 4.9021e-01, -7.9675e-01,  8.8077e-01,  4.4174e-01,  3.4299e-02,\n",
      "           4.9021e-01, -5.7792e-01,  3.4299e-02,  5.2806e-01,  1.4006e+00,\n",
      "          -1.3848e+00, -1.5484e+00, -2.9756e-01]]]) \n",
      "\n",
      "\n",
      "CNN output:  torch.Size([2, 10, 13]) \n",
      " tensor([[[0.1342, 0.0000, 0.1268, 0.0218, 0.0000, 0.1034, 0.1034, 0.1034,\n",
      "          0.1034, 0.1034, 0.1034, 0.1582, 0.0000],\n",
      "         [0.0000, 0.0000, 0.3364, 0.0000, 0.1733, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1785, 0.0000, 0.0405, 0.0000, 0.0609, 0.0609, 0.0609,\n",
      "          0.0609, 0.0609, 0.0609, 0.0000, 0.0000],\n",
      "         [0.2388, 0.1553, 0.0000, 0.5565, 0.5615, 0.5991, 0.5991, 0.5991,\n",
      "          0.5991, 0.5991, 0.5991, 0.5975, 0.3194],\n",
      "         [0.0000, 0.0000, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0848, 0.0371, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1448],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.1368, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0664, 0.0957, 0.0850, 0.1856, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1076, 0.0770, 0.1826, 0.4320, 0.4799, 0.2162, 0.2406, 0.5772,\n",
      "          0.0000, 0.5992, 0.1059, 0.0000, 0.0000],\n",
      "         [0.1194, 0.1257, 0.0000, 0.0153, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0421, 0.1871, 0.0000, 0.1005, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2845, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0623, 0.2330, 0.1216, 0.0214, 0.0995, 0.0000, 0.1817, 0.2246,\n",
      "          0.0000, 0.0000, 0.3696, 0.1829, 0.1920],\n",
      "         [0.2853, 0.3538, 0.0000, 0.2668, 0.2968, 0.5609, 0.3091, 0.3397,\n",
      "          0.2998, 0.4245, 0.0115, 0.0000, 0.1553],\n",
      "         [0.0615, 0.0000, 0.0822, 0.2872, 0.3838, 0.0832, 0.1604, 0.1166,\n",
      "          0.0000, 0.2252, 0.0000, 0.1097, 0.0000],\n",
      "         [0.1113, 0.0000, 0.0000, 0.0000, 0.0000, 0.1852, 0.0752, 0.0000,\n",
      "          0.0960, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0377, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0515, 0.0000, 0.2352, 0.0831, 0.0425, 0.0227, 0.1436,\n",
      "          0.1073, 0.2817, 0.3214, 0.0825, 0.0000]]])\n",
      "\n",
      "Maxpool output:  torch.Size([2, 10, 4]) \n",
      " tensor([[[0.1342, 0.1034, 0.1034, 0.1582],\n",
      "         [0.3364, 0.1733, 0.0000, 0.0000],\n",
      "         [0.1785, 0.0609, 0.0609, 0.0609],\n",
      "         [0.2388, 0.5991, 0.5991, 0.5991],\n",
      "         [0.2157, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0848, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1368, 0.0000, 0.0000],\n",
      "         [0.0957, 0.1856, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1826, 0.4799, 0.5772, 0.5992],\n",
      "         [0.1257, 0.0153, 0.0421, 0.1871],\n",
      "         [0.0000, 0.0000, 0.2845, 0.0000],\n",
      "         [0.2330, 0.0995, 0.2246, 0.3696],\n",
      "         [0.3538, 0.5609, 0.3397, 0.4245],\n",
      "         [0.0822, 0.3838, 0.1604, 0.2252],\n",
      "         [0.1113, 0.1852, 0.0960, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0377],\n",
      "         [0.0515, 0.2352, 0.1436, 0.3214]]])\n",
      "\n",
      "Linear input:  torch.Size([2, 10]) \n",
      " tensor([[0.1582, 0.3364, 0.1785, 0.5991, 0.2157, 0.0848, 0.0000, 0.0000, 0.1368,\n",
      "         0.1856],\n",
      "        [0.5992, 0.1871, 0.2845, 0.3696, 0.5609, 0.3838, 0.1852, 0.0000, 0.0377,\n",
      "         0.3214]])\n",
      "\n",
      "Linear Output:\n",
      " tensor([[-0.2351],\n",
      "        [-0.2623]])\n",
      "\n",
      "Sigmoid:\n",
      " tensor([[0.4415],\n",
      "        [0.4348]])\n",
      "\n",
      "Y Output Tag: \n",
      " tensor([[0.],\n",
      "        [0.]])\n",
      "\n",
      "Actual Output: \n",
      "[tensor(1), tensor(0)]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in sample_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i) for i in x_batch]\n",
    "        y_batch = [torch.tensor(i) for i in y_batch]\n",
    "        \n",
    "        \n",
    "        print(\"X batch: \")\n",
    "        pprint(x_batch)\n",
    "        print(\"\\ny batch: \")\n",
    "        pprint(y_batch)\n",
    "        \n",
    "        y_out = cnn_model_sample(x_batch)\n",
    "                        \n",
    "        y_out_tag = torch.round(y_out)\n",
    "        print(\"\\nY Output Tag: \\n\", y_out_tag)\n",
    "        \n",
    "        \n",
    "        print(\"\\nActual Output: \")\n",
    "        print(y_batch)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 512\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.005\n",
    "STACKED_LAYERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestData(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=1, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size, stacked_layers):\n",
    "        super(ModelCNN, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=64, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding = 1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.linear = nn.Linear(in_features = 32, out_features=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        \n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        embeds_t = embeds.transpose(1, 2)\n",
    "        \n",
    "        cnn1 = self.relu(self.conv1(embeds_t))\n",
    "        cnn1 = self.dropout(cnn1)\n",
    "        cnn2 = self.relu(self.conv2(cnn1))\n",
    "                \n",
    "        linear_in, _ = torch.max(cnn2, dim = 2)\n",
    "        \n",
    "        linear_out = self.linear(linear_in)\n",
    "        \n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCNN(\n",
      "  (word_embeddings): Embedding(797, 512)\n",
      "  (conv1): Conv1d(512, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_model = ModelCNN(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE, target_size=len(tag2idx), stacked_layers=STACKED_LAYERS)\n",
    "\n",
    "cnn_model.to(device)\n",
    "print(cnn_model)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer =  optim.Adam(cnn_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.69614 | Acc: 46.0\n",
      "Epoch 002: | Loss: 0.60907 | Acc: 71.0\n",
      "Epoch 003: | Loss: 0.48153 | Acc: 82.0\n",
      "Epoch 004: | Loss: 0.32296 | Acc: 96.0\n",
      "Epoch 005: | Loss: 0.17984 | Acc: 96.0\n",
      "Epoch 006: | Loss: 0.08349 | Acc: 100.0\n",
      "Epoch 007: | Loss: 0.04535 | Acc: 100.0\n",
      "Epoch 008: | Loss: 0.02509 | Acc: 100.0\n",
      "Epoch 009: | Loss: 0.01347 | Acc: 100.0\n",
      "Epoch 010: | Loss: 0.00928 | Acc: 100.0\n",
      "Epoch 011: | Loss: 0.00625 | Acc: 100.0\n",
      "Epoch 012: | Loss: 0.00550 | Acc: 100.0\n",
      "Epoch 013: | Loss: 0.00519 | Acc: 100.0\n",
      "Epoch 014: | Loss: 0.00380 | Acc: 100.0\n",
      "Epoch 015: | Loss: 0.00293 | Acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "cnn_model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = cnn_model(x_batch)\n",
    "                \n",
    "        loss = criterion(y_pred.squeeze(), y_batch.float())\n",
    "        acc = binary_acc(y_pred.squeeze(), y_batch.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "        \n",
    "        y_pred = cnn_model(x_batch)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred_tag = torch.round(y_pred)\n",
    "\n",
    "        y_out_tags_list.append(y_pred_tag.squeeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = [a.squeeze().tolist() for a in y_out_tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 16]\n",
      " [43 80]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76       109\n",
      "           1       0.83      0.65      0.73       123\n",
      "\n",
      "    accuracy                           0.75       232\n",
      "   macro avg       0.76      0.75      0.74       232\n",
      "weighted avg       0.76      0.75      0.74       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence                                                                        : Sentiment      \n",
      "\n",
      "boyfriend tried the chicken salad and fell love                                 :   1.0\n",
      "\n",
      "have watched their prices portions get and management attitudes                 :   0.0\n",
      "\n",
      "the were the worst ever tasted                                                  :   0.0\n",
      "\n",
      "ate there twice last visit and especially enjoyed the salmon salad              :   0.0\n",
      "\n",
      "which are small and not worth the price                                         :   0.0\n",
      "\n",
      "the chicken dishes are the beef like                                            :   1.0\n",
      "\n",
      "all all excellent restaurant great service menu and beautiful setting           :   1.0\n",
      "\n",
      "went and had fantastic                                                          :   1.0\n",
      "\n",
      "far the best have ever had                                                      :   1.0\n",
      "\n",
      "the was melt your mouth fresh                                                   :   0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{:80}: {:15}\\n'.format(\"Sentence\", \"Sentiment\"))\n",
    "for sentence, tag in zip(X_test[:10], y_out_tags_list[:10]):\n",
    "    s = \" \".join([idx2word[w] for w in sentence])\n",
    "    print('{:80}: {:5}\\n'.format(s, tag))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

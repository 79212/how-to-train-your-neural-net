{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Binary Text Classification using RNNs\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)  \n",
    "\n",
    "This notebook takes you through the implementation of binary text classification in the form of sentiment analysis on yelp reviews using RNNs in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7176a8d9b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0                           Wow... Loved this place.    1\n",
       "1                                 Crust is not good.    0\n",
       "2          Not tasty and the texture was just nasty.    0\n",
       "3  Stopped by during the late May bank holiday of...    1\n",
       "4  The selection on the menu was great and so wer...    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../data/nlp/text_classification/yelp_labelled.txt\", sep=\"\\t\", header=None, names=['text', 'tag'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [t for t in df['text'].to_list()]\n",
    "tag_list = [t for t in df['tag'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crust is not good.',\n",
       " 'Not tasty and the texture was just nasty.',\n",
       " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
       " 'The selection on the menu was great and so were the prices.',\n",
       " 'Now I am getting angry and I want my damn pho.',\n",
       " \"Honeslty it didn't taste THAT fresh.)\",\n",
       " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
       " 'The fries were great too.',\n",
       " 'A great touch.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "sentence_list = [s.lower() for s in sentence_list]\n",
    "\n",
    "# Remove non alphavets\n",
    "regex_remove_nonalphabets = re.compile('[^a-zA-Z]')\n",
    "sentence_list = [regex_remove_nonalphabets.sub(' ', s) for s in sentence_list]\n",
    "\n",
    "# Remove words with less than 2 letters\n",
    "regex_remove_shortwords = re.compile(r'\\b\\w{1,2}\\b')\n",
    "sentence_list = [regex_remove_shortwords.sub(\"\", s) for s in sentence_list]\n",
    "\n",
    "# Remove words that appear only once\n",
    "c = Counter(w for s in sentence_list for w in s.split())\n",
    "sentence_list = [' '.join(y for y in x.split() if c[y] > 1) for x in sentence_list]\n",
    "\n",
    "# Strip extra whitespaces\n",
    "sentence_list = [\" \".join(s.split()) for s in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crust not good',\n",
       " 'not tasty and the texture was just nasty',\n",
       " 'stopped during the late may off recommendation and loved',\n",
       " 'the selection the menu was great and were the prices',\n",
       " 'now getting and want damn pho',\n",
       " 'didn taste that fresh',\n",
       " 'the potatoes were like and you could tell they had been made time being kept under',\n",
       " 'the fries were great too',\n",
       " 'great touch']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word-vocablury: 844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sentence in sentence_list:\n",
    "    for w in sentence.split():\n",
    "        words.append(w)\n",
    "    \n",
    "words = list(set(words))\n",
    "print(f\"Size of word-vocablury: {len(words)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tag-vocab: 2\n",
      "\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in tag_list:\n",
    "    tags.append(tag)\n",
    "tags = list(set(tags))\n",
    "print(f\"Size of tag-vocab: {len(tags)}\\n\")\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {word: i for i, word in enumerate(tags)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the input and output to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[178, 617, 319, 120],\n",
       " [548, 467, 512],\n",
       " [467, 506, 768, 289, 317, 834, 214, 174]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[word2idx[w] for w in s.split()] for s in sentence_list]\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [tag2idx[t] for t in tag_list]\n",
    "y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  700\n",
      "X_test size:  300\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train size: \", len(X_train))\n",
    "print(\"X_test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_SAMPLE = 2\n",
    "EMBEDDING_SIZE_SAMPLE = 5\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE_SAMPLE = 3\n",
    "STACKED_LAYERS_SAMPLE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = SampleData(X_train, y_train)\n",
    "sample_loader = DataLoader(sample_data, batch_size=BATCH_SIZE_SAMPLE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[727, 592, 350, 360], [289, 834, 699, 243, 554, 221, 768, 834]] \n",
      "\n",
      " [1, 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tl = iter(sample_loader)\n",
    "\n",
    "i,j = map(list, zip(*next(tl)))\n",
    "\n",
    "print(i,\"\\n\\n\", j, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample RNN class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGRUSample(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size, stacked_layers):\n",
    "        super(ModelGRUSample, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.gru = nn.GRU(input_size = embedding_size, hidden_size = hidden_size, batch_first = True, num_layers=stacked_layers)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=1)\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        print(\"\\nList of tensor lengths in a batch: \")\n",
    "        len_list = list(map(len, x_batch))\n",
    "        print(len_list)\n",
    "        \n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        print(\"\\nPadded X_batch: \", padded_batch.size(), \"\\n\", padded_batch)\n",
    "\n",
    "        \n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        print(\"\\nEmbeddings: \", embeds.size(), \"\\n\", embeds)\n",
    "\n",
    "        pack_embeds = pack_padded_sequence(embeds, lengths=len_list, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        rnn_out, rnn_hidden = self.gru(pack_embeds)\n",
    "        print(\"\\nRNN hidden last layer: \", rnn_hidden.size(), \"\\n\", rnn_hidden)\n",
    "        \n",
    "        linear_out = self.linear(rnn_hidden)\n",
    "        print(\"\\nLinear Output: \", linear_out.size(), \"\\n\", linear_out)\n",
    "        \n",
    "        y_out = torch.sigmoid(linear_out)\n",
    "        y_out = y_out[-1]\n",
    "        print(\"\\nSigmoid:\\n\", y_out)\n",
    "\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelGRUSample(\n",
      "  (word_embeddings): Embedding(844, 5)\n",
      "  (gru): GRU(5, 3, num_layers=4, batch_first=True)\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gru_model_sample = ModelGRUSample(embedding_size=EMBEDDING_SIZE_SAMPLE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE_SAMPLE, target_size=len(tag2idx), stacked_layers=STACKED_LAYERS_SAMPLE)\n",
    "print(gru_model_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output.\n",
    "\n",
    "output = [batch size, sent len, hid dim]  \n",
    "hidden = [batch size, 1, hid dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: \n",
      "[tensor([727, 592, 350, 360]), tensor([289, 834, 699, 243, 554, 221, 768, 834])]\n",
      "\n",
      "y batch: \n",
      "[tensor(1), tensor(0)]\n",
      "\n",
      "List of tensor lengths in a batch: \n",
      "[4, 8]\n",
      "\n",
      "Padded X_batch:  torch.Size([2, 8]) \n",
      " tensor([[727, 592, 350, 360,   0,   0,   0,   0],\n",
      "        [289, 834, 699, 243, 554, 221, 768, 834]])\n",
      "\n",
      "Embeddings:  torch.Size([2, 8, 5]) \n",
      " tensor([[[ 0.4587,  1.0819, -1.2467,  0.3633,  0.4429],\n",
      "         [-0.4451, -0.6583,  1.6095,  0.3690, -0.2631],\n",
      "         [ 1.7288, -0.4040, -0.8616,  1.7713,  0.8700],\n",
      "         [ 1.1721, -1.4974,  1.0943, -1.3289,  1.2544],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798],\n",
      "         [-0.6540, -1.6095, -0.1002, -0.6092, -0.9798]],\n",
      "\n",
      "        [[-1.5452,  0.0326,  0.8171, -0.0246, -0.3599],\n",
      "         [-1.0061, -1.1881,  0.4155, -0.4172, -2.2063],\n",
      "         [ 0.8112, -0.4186, -0.1767, -0.5618,  0.2393],\n",
      "         [ 0.3384, -1.1396, -0.3602, -0.3941,  0.0948],\n",
      "         [-0.4083, -1.1388, -0.1384, -2.1125,  0.9048],\n",
      "         [ 1.7252,  1.3536,  1.6513, -0.0177, -1.2269],\n",
      "         [-1.4189,  0.0945, -0.7090,  0.4575,  0.9523],\n",
      "         [-1.0061, -1.1881,  0.4155, -0.4172, -2.2063]]])\n",
      "\n",
      "RNN hidden last layer:  torch.Size([4, 2, 3]) \n",
      " tensor([[[ 0.0398, -0.9731,  0.4790],\n",
      "         [-0.1735,  0.2075,  0.0057]],\n",
      "\n",
      "        [[-0.2706,  0.5936,  0.4596],\n",
      "         [ 0.0220,  0.4320,  0.3315]],\n",
      "\n",
      "        [[ 0.5411,  0.1503, -0.8814],\n",
      "         [ 0.4806,  0.1860, -0.8623]],\n",
      "\n",
      "        [[ 0.2655, -0.3307, -0.5849],\n",
      "         [ 0.2485, -0.3106, -0.6057]]])\n",
      "\n",
      "Linear Output:  torch.Size([4, 2, 1]) \n",
      " tensor([[[-0.2374],\n",
      "         [ 0.5488]],\n",
      "\n",
      "        [[ 0.5273],\n",
      "         [ 0.3840]],\n",
      "\n",
      "        [[ 0.6040],\n",
      "         [ 0.6381]],\n",
      "\n",
      "        [[ 0.4105],\n",
      "         [ 0.4366]]])\n",
      "\n",
      "Sigmoid:\n",
      " tensor([[0.6012],\n",
      "        [0.6074]])\n",
      "\n",
      "Y Output Tag: \n",
      " tensor([[1.],\n",
      "        [1.]])\n",
      "\n",
      "Actual Output: \n",
      "[tensor(1), tensor(0)]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in sample_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i) for i in x_batch]\n",
    "        y_batch = [torch.tensor(i) for i in y_batch]\n",
    "        \n",
    "        \n",
    "        print(\"X batch: \")\n",
    "        pprint(x_batch)\n",
    "        print(\"\\ny batch: \")\n",
    "        pprint(y_batch)\n",
    "        \n",
    "        y_out = gru_model_sample(x_batch)\n",
    "                        \n",
    "        y_out_tag = torch.round(y_out)\n",
    "        print(\"\\nY Output Tag: \\n\", y_out_tag)\n",
    "        \n",
    "        \n",
    "        print(\"\\nActual Output: \")\n",
    "        print(y_batch)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acutal Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 256\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "STACKED_LAYERS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestData(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=1, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, target_size, stacked_layers):\n",
    "        super(ModelLSTM, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, hidden_size = hidden_size, batch_first = True, num_layers = stacked_layers, dropout = 0.3)\n",
    "        self.linear = nn.Linear(in_features = hidden_size, out_features=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        len_list = list(map(len, x_batch))\n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        pack_embeds = pack_padded_sequence(embeds, lengths=len_list, batch_first=True, enforce_sorted=False)\n",
    "        rnn_out, (rnn_h, rnn_c) = self.lstm(pack_embeds)\n",
    "        linear_out = self.linear(self.tanh(rnn_h))\n",
    "        y_out = linear_out[-1]\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelLSTM(\n",
      "  (word_embeddings): Embedding(844, 256)\n",
      "  (lstm): LSTM(256, 8, num_layers=8, batch_first=True, dropout=0.3)\n",
      "  (linear): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm_model = ModelLSTM(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), hidden_size=HIDDEN_SIZE, target_size=len(tag2idx), stacked_layers=STACKED_LAYERS)\n",
    "\n",
    "lstm_model.to(device)\n",
    "print(lstm_model)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer =  optim.Adam(lstm_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.69650 | Acc: 58.0\n",
      "Epoch 002: | Loss: 0.69541 | Acc: 58.0\n",
      "Epoch 003: | Loss: 0.69487 | Acc: 58.0\n",
      "Epoch 004: | Loss: 0.69375 | Acc: 58.0\n",
      "Epoch 005: | Loss: 0.69320 | Acc: 58.0\n",
      "Epoch 006: | Loss: 0.69265 | Acc: 58.0\n",
      "Epoch 007: | Loss: 0.69314 | Acc: 58.0\n",
      "Epoch 008: | Loss: 0.69256 | Acc: 58.0\n",
      "Epoch 009: | Loss: 0.69163 | Acc: 58.0\n",
      "Epoch 010: | Loss: 0.69232 | Acc: 58.0\n",
      "Epoch 011: | Loss: 0.69193 | Acc: 58.0\n",
      "Epoch 012: | Loss: 0.69257 | Acc: 58.0\n",
      "Epoch 013: | Loss: 0.69203 | Acc: 57.0\n",
      "Epoch 014: | Loss: 0.69166 | Acc: 58.0\n",
      "Epoch 015: | Loss: 0.69106 | Acc: 62.0\n",
      "Epoch 016: | Loss: 0.69195 | Acc: 60.0\n",
      "Epoch 017: | Loss: 0.69239 | Acc: 57.0\n",
      "Epoch 018: | Loss: 0.69153 | Acc: 58.0\n",
      "Epoch 019: | Loss: 0.68823 | Acc: 67.0\n",
      "Epoch 020: | Loss: 0.68475 | Acc: 70.0\n",
      "Epoch 021: | Loss: 0.67692 | Acc: 78.0\n",
      "Epoch 022: | Loss: 0.66500 | Acc: 80.0\n",
      "Epoch 023: | Loss: 0.64755 | Acc: 83.0\n",
      "Epoch 024: | Loss: 0.62325 | Acc: 80.0\n",
      "Epoch 025: | Loss: 0.59756 | Acc: 82.0\n",
      "Epoch 026: | Loss: 0.56563 | Acc: 85.0\n",
      "Epoch 027: | Loss: 0.53810 | Acc: 85.0\n",
      "Epoch 028: | Loss: 0.50294 | Acc: 88.0\n",
      "Epoch 029: | Loss: 0.49204 | Acc: 85.0\n",
      "Epoch 030: | Loss: 0.46152 | Acc: 90.0\n",
      "Epoch 031: | Loss: 0.44950 | Acc: 88.0\n",
      "Epoch 032: | Loss: 0.43096 | Acc: 87.0\n",
      "Epoch 033: | Loss: 0.39548 | Acc: 90.0\n",
      "Epoch 034: | Loss: 0.39652 | Acc: 90.0\n",
      "Epoch 035: | Loss: 0.39531 | Acc: 90.0\n",
      "Epoch 036: | Loss: 0.36143 | Acc: 92.0\n",
      "Epoch 037: | Loss: 0.34850 | Acc: 93.0\n",
      "Epoch 038: | Loss: 0.34932 | Acc: 90.0\n",
      "Epoch 039: | Loss: 0.32864 | Acc: 95.0\n",
      "Epoch 040: | Loss: 0.31616 | Acc: 98.0\n",
      "Epoch 041: | Loss: 0.30230 | Acc: 97.0\n",
      "Epoch 042: | Loss: 0.29047 | Acc: 97.0\n",
      "Epoch 043: | Loss: 0.28979 | Acc: 97.0\n",
      "Epoch 044: | Loss: 0.27619 | Acc: 93.0\n",
      "Epoch 045: | Loss: 0.26187 | Acc: 93.0\n",
      "Epoch 046: | Loss: 0.26891 | Acc: 92.0\n",
      "Epoch 047: | Loss: 0.26700 | Acc: 97.0\n",
      "Epoch 048: | Loss: 0.25340 | Acc: 90.0\n",
      "Epoch 049: | Loss: 0.26535 | Acc: 95.0\n",
      "Epoch 050: | Loss: 0.22529 | Acc: 98.0\n",
      "Epoch 051: | Loss: 0.23877 | Acc: 93.0\n",
      "Epoch 052: | Loss: 0.22973 | Acc: 92.0\n",
      "Epoch 053: | Loss: 0.22219 | Acc: 95.0\n",
      "Epoch 054: | Loss: 0.21723 | Acc: 97.0\n",
      "Epoch 055: | Loss: 0.20150 | Acc: 95.0\n",
      "Epoch 056: | Loss: 0.21164 | Acc: 98.0\n",
      "Epoch 057: | Loss: 0.19424 | Acc: 95.0\n",
      "Epoch 058: | Loss: 0.20216 | Acc: 93.0\n",
      "Epoch 059: | Loss: 0.17790 | Acc: 97.0\n",
      "Epoch 060: | Loss: 0.18045 | Acc: 95.0\n",
      "Epoch 061: | Loss: 0.17888 | Acc: 98.0\n",
      "Epoch 062: | Loss: 0.17824 | Acc: 97.0\n",
      "Epoch 063: | Loss: 0.17489 | Acc: 97.0\n",
      "Epoch 064: | Loss: 0.17775 | Acc: 95.0\n",
      "Epoch 065: | Loss: 0.17611 | Acc: 93.0\n",
      "Epoch 066: | Loss: 0.16219 | Acc: 98.0\n",
      "Epoch 067: | Loss: 0.14412 | Acc: 97.0\n",
      "Epoch 068: | Loss: 0.14667 | Acc: 97.0\n",
      "Epoch 069: | Loss: 0.15138 | Acc: 97.0\n",
      "Epoch 070: | Loss: 0.14210 | Acc: 98.0\n",
      "Epoch 071: | Loss: 0.12643 | Acc: 98.0\n",
      "Epoch 072: | Loss: 0.14526 | Acc: 97.0\n",
      "Epoch 073: | Loss: 0.14361 | Acc: 97.0\n",
      "Epoch 074: | Loss: 0.13855 | Acc: 98.0\n",
      "Epoch 075: | Loss: 0.12968 | Acc: 97.0\n",
      "Epoch 076: | Loss: 0.12110 | Acc: 98.0\n",
      "Epoch 077: | Loss: 0.11667 | Acc: 98.0\n",
      "Epoch 078: | Loss: 0.11800 | Acc: 95.0\n",
      "Epoch 079: | Loss: 0.11521 | Acc: 97.0\n",
      "Epoch 080: | Loss: 0.10858 | Acc: 98.0\n",
      "Epoch 081: | Loss: 0.12174 | Acc: 97.0\n",
      "Epoch 082: | Loss: 0.11822 | Acc: 98.0\n",
      "Epoch 083: | Loss: 0.11440 | Acc: 95.0\n",
      "Epoch 084: | Loss: 0.10406 | Acc: 98.0\n",
      "Epoch 085: | Loss: 0.12110 | Acc: 97.0\n",
      "Epoch 086: | Loss: 0.11098 | Acc: 97.0\n",
      "Epoch 087: | Loss: 0.10434 | Acc: 98.0\n",
      "Epoch 088: | Loss: 0.10944 | Acc: 98.0\n",
      "Epoch 089: | Loss: 0.10804 | Acc: 98.0\n",
      "Epoch 090: | Loss: 0.10543 | Acc: 98.0\n",
      "Epoch 091: | Loss: 0.10171 | Acc: 98.0\n",
      "Epoch 092: | Loss: 0.09524 | Acc: 98.0\n",
      "Epoch 093: | Loss: 0.10526 | Acc: 97.0\n",
      "Epoch 094: | Loss: 0.11264 | Acc: 97.0\n",
      "Epoch 095: | Loss: 0.09305 | Acc: 97.0\n",
      "Epoch 096: | Loss: 0.10220 | Acc: 97.0\n",
      "Epoch 097: | Loss: 0.08480 | Acc: 98.0\n",
      "Epoch 098: | Loss: 0.10255 | Acc: 100.0\n",
      "Epoch 099: | Loss: 0.09743 | Acc: 98.0\n",
      "Epoch 100: | Loss: 0.07764 | Acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = lstm_model(x_batch)      \n",
    "        \n",
    "        loss = criterion(y_pred.squeeze(1), y_batch.float())\n",
    "        acc = binary_acc(y_pred.squeeze(1), y_batch.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "        \n",
    "        y_pred = lstm_model(x_batch)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred_tag = torch.round(y_pred)\n",
    "\n",
    "        y_out_tags_list.append(y_pred_tag.squeeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = [a.squeeze().tolist() for a in y_out_tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  52]\n",
      " [ 39 102]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       159\n",
      "           1       0.66      0.72      0.69       141\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.70      0.70      0.70       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence                                                                        : Sentiment      \n",
      "\n",
      "omg the food was                                                                :   0.0\n",
      "\n",
      "very filling meals                                                              :   1.0\n",
      "\n",
      "too bad the food damn                                                           :   0.0\n",
      "\n",
      "far the best have ever had                                                      :   1.0\n",
      "\n",
      "think this restaurant from not trying hard enough                               :   1.0\n",
      "\n",
      "awful service                                                                   :   1.0\n",
      "\n",
      "the owners are super friendly and the staff                                     :   1.0\n",
      "\n",
      "dont think will back for very long time                                         :   0.0\n",
      "\n",
      "their chicken fried steak and eggs all time favorite                            :   1.0\n",
      "\n",
      "after all the reviews couldn wait eat here what disappointment                  :   0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{:80}: {:15}\\n'.format(\"Sentence\", \"Sentiment\"))\n",
    "for sentence, tag in zip(X_test[:10], y_out_tags_list[:10]):\n",
    "    s = \" \".join([idx2word[w] for w in sentence])\n",
    "    print('{:80}: {:5}\\n'.format(s, tag))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

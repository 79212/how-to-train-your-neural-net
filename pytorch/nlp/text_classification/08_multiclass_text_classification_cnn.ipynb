{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Multi-Class Text Classification using CNNs\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)  \n",
    "\n",
    "This notebook takes you through the implementation of binary text classification in the form of sentiment analysis on yelp reviews using CNNs in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd8c5f96550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../data/nlp/text_classification/bbc-text.csv\")\n",
    "df = df.rename(columns = {'category':'tag'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [t for t in df['text'].to_list()]\n",
    "tag_list = [t for t in df['tag'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tv future in the hands of viewers with home theatre systems  plasma high-definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in five years  time.  that is according to an expert panel which gathered at the annual consumer electronics show in las vegas to discuss how these new technologies will impact one of our favourite pastimes. with the us leading the trend  programmes and other content will be delivered to viewers via home networks  through cable  satellite  telecoms companies  and broadband service providers to front rooms and portable devices.  one of the most talked-about technologies of ces has been digital and personal video recorders (dvr and pvr). these set-top boxes  like the us s tivo and the uk s sky+ system  allow people to record  store  play  pause and forward wind tv programmes when they want.  essentially  the technology allows for much more personalised tv. they are also being built-in to high-definition tv sets  which are big business in japan and the us  but slower to take off in europe because of the lack of high-definition programming. not only can people forward wind through adverts  they can also forget about abiding by network and channel schedules  putting together their own a-la-carte entertainment. but some us networks and cable and satellite companies are worried about what it means for them in terms of advertising revenues as well as  brand identity  and viewer loyalty to channels. although the us leads in this technology at the moment  it is also a concern that is being raised in europe  particularly with the growing uptake of services like sky+.  what happens here today  we will see in nine months to a years  time in the uk   adam hume  the bbc broadcast s futurologist told the bbc news website. for the likes of the bbc  there are no issues of lost advertising revenue yet. it is a more pressing issue at the moment for commercial uk broadcasters  but brand loyalty is important for everyone.  we will be talking more about content brands rather than network brands   said tim hanlon  from brand communications firm starcom mediavest.  the reality is that with broadband connections  anybody can be the producer of content.  he added:  the challenge now is that it is hard to promote a programme with so much choice.   what this means  said stacey jolna  senior vice president of tv guide tv group  is that the way people find the content they want to watch has to be simplified for tv viewers. it means that networks  in us terms  or channels could take a leaf out of google s book and be the search engine of the future  instead of the scheduler to help people find what they want to watch. this kind of channel model might work for the younger ipod generation which is used to taking control of their gadgets and what they play on them. but it might not suit everyone  the panel recognised. older generations are more comfortable with familiar schedules and channel brands because they know what they are getting. they perhaps do not want so much of the choice put into their hands  mr hanlon suggested.  on the other end  you have the kids just out of diapers who are pushing buttons already - everything is possible and available to them   said mr hanlon.  ultimately  the consumer will tell the market they want.   of the 50 000 new gadgets and technologies being showcased at ces  many of them are about enhancing the tv-watching experience. high-definition tv sets are everywhere and many new models of lcd (liquid crystal display) tvs have been launched with dvr capability built into them  instead of being external boxes. one such example launched at the show is humax s 26-inch lcd tv with an 80-hour tivo dvr and dvd recorder. one of the us s biggest satellite tv companies  directtv  has even launched its own branded dvr at the show with 100-hours of recording capability  instant replay  and a search function. the set can pause and rewind tv for up to 90 hours. and microsoft chief bill gates announced in his pre-show keynote speech a partnership with tivo  called tivotogo  which means people can play recorded programmes on windows pcs and mobile devices. all these reflect the increasing trend of freeing up multimedia so that people can watch what they want  when they want.',\n",
       " 'worldcom boss  left books alone  former worldcom boss bernie ebbers  who is accused of overseeing an $11bn (Â£5.8bn) fraud  never made accounting decisions  a witness has told jurors.  david myers made the comments under questioning by defence lawyers who have been arguing that mr ebbers was not responsible for worldcom s problems. the phone company collapsed in 2002 and prosecutors claim that losses were hidden to protect the firm s shares. mr myers has already pleaded guilty to fraud and is assisting prosecutors.  on monday  defence lawyer reid weingarten tried to distance his client from the allegations. during cross examination  he asked mr myers if he ever knew mr ebbers  make an accounting decision  .  not that i am aware of   mr myers replied.  did you ever know mr ebbers to make an accounting entry into worldcom books   mr weingarten pressed.  no   replied the witness. mr myers has admitted that he ordered false accounting entries at the request of former worldcom chief financial officer scott sullivan. defence lawyers have been trying to paint mr sullivan  who has admitted fraud and will testify later in the trial  as the mastermind behind worldcom s accounting house of cards.  mr ebbers  team  meanwhile  are looking to portray him as an affable boss  who by his own admission is more pe graduate than economist. whatever his abilities  mr ebbers transformed worldcom from a relative unknown into a $160bn telecoms giant and investor darling of the late 1990s. worldcom s problems mounted  however  as competition increased and the telecoms boom petered out. when the firm finally collapsed  shareholders lost about $180bn and 20 000 workers lost their jobs. mr ebbers  trial is expected to last two months and if found guilty the former ceo faces a substantial jail sentence. he has firmly declared his innocence.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tech', 'business']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "sentence_list = [s.lower() for s in sentence_list]\n",
    "\n",
    "# Remove non alphavets\n",
    "regex_remove_nonalphabets = re.compile('[^a-zA-Z]')\n",
    "sentence_list = [regex_remove_nonalphabets.sub(' ', s) for s in sentence_list]\n",
    "\n",
    "# Remove words with less than 2 letters\n",
    "# regex_remove_shortwords = re.compile(r'\\b\\w{1,2}\\b')\n",
    "# sentence_list = [regex_remove_shortwords.sub(\"\", s) for s in sentence_list]\n",
    "\n",
    "# Remove words that appear only once\n",
    "c = Counter(w for s in sentence_list for w in s.split())\n",
    "sentence_list = [' '.join(y for y in x.split() if c[y] > 1) for x in sentence_list]\n",
    "\n",
    "# Strip extra whitespaces\n",
    "sentence_list = [\" \".join(s.split()) for s in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tv future in the hands of viewers with home theatre systems plasma high definition tvs and digital video recorders moving into the living room the way people watch tv will be radically different in five years time that is according to an expert panel which gathered at the annual consumer electronics show in las vegas to discuss how these new technologies will impact one of our favourite with the us leading the trend programmes and other content will be delivered to viewers via home networks through cable satellite telecoms companies and broadband service providers to front rooms and portable devices one of the most talked about technologies of ces has been digital and personal video recorders dvr and pvr these set top boxes like the us s tivo and the uk s sky system allow people to record store play pause and forward wind tv programmes when they want essentially the technology allows for much more personalised tv they are also being built in to high definition tv sets which are big business in japan and the us but slower to take off in europe because of the lack of high definition programming not only can people forward wind through adverts they can also forget about abiding by network and channel schedules putting together their own a la carte entertainment but some us networks and cable and satellite companies are worried about what it means for them in terms of advertising revenues as well as brand identity and viewer loyalty to channels although the us leads in this technology at the moment it is also a concern that is being raised in europe particularly with the growing uptake of services like sky what happens here today we will see in nine months to a years time in the uk adam the bbc broadcast s futurologist told the bbc news website for the likes of the bbc there are no issues of lost advertising revenue yet it is a more pressing issue at the moment for commercial uk broadcasters but brand loyalty is important for everyone we will be talking more about content brands rather than network brands said tim hanlon from brand communications firm the reality is that with broadband connections anybody can be the producer of content he added the challenge now is that it is hard to promote a programme with so much choice what this means said senior vice president of tv guide tv group is that the way people find the content they want to watch has to be simplified for tv viewers it means that networks in us terms or channels could take a leaf out of google s book and be the search engine of the future instead of the to help people find what they want to watch this kind of channel model might work for the younger ipod generation which is used to taking control of their gadgets and what they play on them but it might not suit everyone the panel recognised older generations are more comfortable with familiar schedules and channel brands because they know what they are getting they perhaps do not want so much of the choice put into their hands mr hanlon suggested on the other end you have the kids just out of who are pushing buttons already everything is possible and available to them said mr hanlon ultimately the consumer will tell the market they want of the new gadgets and technologies being showcased at ces many of them are about enhancing the tv watching experience high definition tv sets are everywhere and many new models of lcd liquid crystal display tvs have been launched with dvr capability built into them instead of being external boxes one such example launched at the show is s inch lcd tv with an hour tivo dvr and dvd recorder one of the us s biggest satellite tv companies has even launched its own branded dvr at the show with hours of recording capability instant replay and a search function the set can pause and rewind tv for up to hours and microsoft chief bill gates announced in his pre show keynote speech a partnership with tivo called which means people can play recorded programmes on windows pcs and mobile devices all these reflect the increasing trend of freeing up multimedia so that people can watch what they want when they want',\n",
       " 'worldcom boss left books alone former worldcom boss bernie ebbers who is accused of overseeing an bn bn fraud never made accounting decisions a witness has told jurors david myers made the comments under questioning by defence lawyers who have been arguing that mr ebbers was not responsible for worldcom s problems the phone company collapsed in and prosecutors claim that losses were hidden to protect the firm s shares mr myers has already pleaded guilty to fraud and is assisting prosecutors on monday defence lawyer reid weingarten tried to distance his client from the allegations during cross examination he asked mr myers if he ever knew mr ebbers make an accounting decision not that i am aware of mr myers replied did you ever know mr ebbers to make an accounting entry into worldcom books mr weingarten pressed no replied the witness mr myers has admitted that he ordered false accounting entries at the request of former worldcom chief financial officer scott sullivan defence lawyers have been trying to paint mr sullivan who has admitted fraud and will testify later in the trial as the mastermind behind worldcom s accounting house of cards mr ebbers team meanwhile are looking to portray him as an boss who by his own admission is more pe graduate than economist whatever his abilities mr ebbers transformed worldcom from a relative unknown into a bn telecoms giant and investor darling of the late s worldcom s problems mounted however as competition increased and the telecoms boom petered out when the firm finally collapsed shareholders lost about bn and workers lost their jobs mr ebbers trial is expected to last two months and if found guilty the former ceo faces a substantial jail sentence he has firmly declared his innocence']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word-vocablury: 18636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sentence in sentence_list:\n",
    "    for w in sentence.split():\n",
    "        words.append(w)\n",
    "    \n",
    "words = list(set(words))\n",
    "print(f\"Size of word-vocablury: {len(words)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocab and dictionary for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tag-vocab: 5\n",
      "\n",
      "['tech', 'sport', 'politics', 'business', 'entertainment']\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in tag_list:\n",
    "    tags.append(tag)\n",
    "tags = list(set(tags))\n",
    "print(f\"Size of tag-vocab: {len(tags)}\\n\")\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output <=> ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tech': 0, 'sport': 1, 'politics': 2, 'business': 3, 'entertainment': 4}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {word: i for i, word in enumerate(tags)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the input and output to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w] for w in s.split()] for s in sentence_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [tag2idx[t] for t in tag_list]\n",
    "y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  1557\n",
      "X_test size:  668\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train size: \", len(X_train))\n",
    "print(\"X_test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_SAMPLE = 2\n",
    "EMBEDDING_SIZE_SAMPLE = 5\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE_SAMPLE = 3\n",
    "STACKED_LAYERS_SAMPLE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = SampleData(X_train, y_train)\n",
    "sample_loader = DataLoader(sample_data, batch_size=BATCH_SIZE_SAMPLE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2946, 1927, 13292, 1281, 13491, 8469, 2946, 16737, 11041, 17222, 13551, 4228, 105, 17222, 13292, 2027, 7294, 11800, 8271, 10190, 105, 5319, 17058, 17041, 1543, 9154, 1454, 6371, 2027, 5226, 1454, 1701, 5417, 13289, 5034, 10729, 2483, 5319, 9868, 4300, 2198, 11366, 17151, 15158, 15356, 8705, 17058, 13196, 5207, 12825, 8732, 8705, 16778, 10527, 9868, 657, 2936, 7670, 9822, 2027, 5226, 5207, 2552, 16726, 7294, 12929, 6923, 16478, 2218, 2959, 14148, 18024, 8705, 1025, 17041, 17253, 16429, 15059, 17489, 5226, 13212, 1869, 105, 15249, 14950, 4041, 13279, 4371, 18185, 10998, 105, 2226, 5207, 1025, 17253, 14510, 8185, 9352, 8533, 7234, 3, 14950, 16778, 10527, 9868, 4274, 14206, 17222, 8345, 13551, 2388, 4654, 12305, 9629, 17017, 7164, 105, 5126, 8883, 1551, 11939, 105, 2748, 17058, 14819, 14950, 5461, 1505, 18600, 2958, 16674, 12929, 13437, 2916, 1869, 8705, 2050, 6813, 12362, 11101, 13411, 8635, 18438, 1927, 12929, 6991, 10440, 16127, 560, 17058, 16922, 560, 5794, 9885, 11101, 15266, 15266, 16184, 1927, 17222, 10791, 16622, 1334, 1454, 892, 12825, 15983, 7234, 317, 10440, 18556, 13595, 3425, 150, 10440, 892, 8450, 6813, 16622, 1334, 12373, 892, 14202, 2216, 17058, 10440, 15387, 13595, 9885, 1927, 17222, 4, 17266, 14032, 16702, 16447, 5897, 17908, 105, 17699, 5794, 2946, 12362, 1927, 16042, 5639, 3012, 105, 12929, 16382, 2916, 17222, 17438, 1454, 14194, 14950, 892, 15878, 3149, 6269, 6564, 10184, 10440, 6522, 10440, 10888, 5417, 17841, 580, 9154, 692, 10440, 10888, 17883, 9885, 8950, 5471, 18600, 9604, 12472, 16622, 1334, 12373, 12362, 3149, 11593, 17928, 10729, 11863, 18600, 1909, 18361, 17058, 10248, 3976, 6522, 3976, 10888, 3878, 1437, 580, 17222, 8901], [15900, 3012, 8635, 1512, 7798, 230, 4270, 724, 17058, 14675, 9138, 3131, 17222, 15900, 3012, 8635, 17222, 7322, 105, 3149, 18111, 7798, 230, 13310, 1025, 9507, 16726, 17222, 1512, 4013, 17222, 17035, 3031, 10729, 14880, 4088, 13317, 8635, 17222, 1857, 105, 12101, 17058, 10029, 7798, 13310, 13255, 16891, 16726, 7332, 13317, 12373, 3031, 10729, 14567, 14507, 14455, 105, 7798, 17222, 230, 1025, 11238, 8057, 18389, 17222, 11466, 17962, 15430, 18417, 7798, 11245, 1881, 17222, 15968, 230, 1025, 16729, 7234, 17222, 18417, 1617, 105, 580, 17222, 14152, 9770, 10729, 17222, 15430, 17596, 105, 18600, 17222, 11673, 9090, 16843, 14675, 17222, 17035, 892, 15960, 1927, 5794, 12373, 892, 18532, 692, 105, 17222, 17598, 105, 16560, 6463, 18389, 12287, 17222, 18099, 18600, 2958, 17222, 13813, 14917, 105, 724, 4270, 17058, 14675, 10888, 6919, 17222, 13859, 13728, 12362, 15158, 105, 17222, 11666, 11686, 12312, 4264, 8635, 8539, 39, 17058, 1815, 1298, 15044, 8635, 17222, 7742, 1334, 15430, 13813, 11589, 4116, 1159, 10729, 12438, 11658, 17512, 105, 1881, 17505, 18600, 17222, 230, 1025, 14827, 1927, 17058, 12373, 12362, 3962, 10729, 11238, 16932, 1927, 7293, 14382, 354, 3670, 15416, 14984, 13310, 17222, 9204, 6695, 17883, 2772, 5240, 4997, 7234, 17222, 16605, 12475, 12080, 11245, 3149, 11466, 11869, 6617, 17222, 17058, 13288, 6540, 6269, 11765, 10038, 12341, 17222, 17035, 9138, 12825, 17222, 6463, 105, 17222, 2537, 8804, 9213, 10888, 1334, 13310, 7798, 3780, 2324, 14322, 5410, 17058, 17681, 5428, 9584, 11238, 17073, 10729, 8621, 4088, 1114, 10729, 17222, 17058]] \n",
      "\n",
      " [1, 3] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tl = iter(sample_loader)\n",
    "\n",
    "i,j = map(list, zip(*next(tl)))\n",
    "\n",
    "print(i,\"\\n\\n\", j, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample CNN class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCNNSample(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, target_size):\n",
    "        super(ModelCNNSample, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=100, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=10, kernel_size=3, stride=1, padding = 1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.linear = nn.Linear(in_features = 10, out_features=target_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_batch):        \n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        print(\"\\nPadded X_batch: \", padded_batch.size(), \"\\n\", padded_batch, \"\\n\")\n",
    "\n",
    "        \n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        print(\"\\nEmbeddings: \", embeds.size(), \"\\n\", embeds, \"\\n\")\n",
    "    \n",
    "        embeds_t = embeds.transpose(1, 2)\n",
    "        print(\"\\nEmbeddings transposed for CNN: \", embeds_t.size(), \"\\n\", embeds_t, \"\\n\")\n",
    "\n",
    "        cnn1 = torch.relu(self.conv1(embeds_t))\n",
    "        cnn2 = torch.relu(self.conv2(cnn1))\n",
    "        print(\"\\nCNN output: \", cnn2.size(), \"\\n\", cnn2)\n",
    "        \n",
    "        maxpool1 = self.maxpool(cnn2)\n",
    "        print(\"\\nMaxpool output: \", maxpool1.size(), \"\\n\", maxpool1)\n",
    "        \n",
    "        linear_in, _ = torch.max(maxpool1, dim = 2)\n",
    "        print(\"\\nLinear input: \", linear_in.size(), \"\\n\", linear_in)\n",
    "\n",
    "\n",
    "        linear_out = self.linear(linear_in)\n",
    "        print(\"\\nLinear Output:\\n\", linear_out)\n",
    "        \n",
    "        y_out = torch.log_softmax(linear_out, dim = 1)\n",
    "        print(\"\\nLog Softmax:\\n\", y_out)\n",
    "\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCNNSample(\n",
      "  (word_embeddings): Embedding(18636, 5)\n",
      "  (conv1): Conv1d(5, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(100, 10, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_model_sample = ModelCNNSample(embedding_size=EMBEDDING_SIZE_SAMPLE, vocab_size=len(word2idx), target_size=len(tag2idx))\n",
    "print(cnn_model_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output.\n",
    "\n",
    "output = [batch size, sent len, hid dim]  \n",
    "hidden = [batch size, 1, hid dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: \n",
      "[tensor([ 2946,  1927, 13292,  1281, 13491,  8469,  2946, 16737, 11041, 17222,\n",
      "        13551,  4228,   105, 17222, 13292,  2027,  7294, 11800,  8271, 10190,\n",
      "          105,  5319, 17058, 17041,  1543,  9154,  1454,  6371,  2027,  5226,\n",
      "         1454,  1701,  5417, 13289,  5034, 10729,  2483,  5319,  9868,  4300,\n",
      "         2198, 11366, 17151, 15158, 15356,  8705, 17058, 13196,  5207, 12825,\n",
      "         8732,  8705, 16778, 10527,  9868,   657,  2936,  7670,  9822,  2027,\n",
      "         5226,  5207,  2552, 16726,  7294, 12929,  6923, 16478,  2218,  2959,\n",
      "        14148, 18024,  8705,  1025, 17041, 17253, 16429, 15059, 17489,  5226,\n",
      "        13212,  1869,   105, 15249, 14950,  4041, 13279,  4371, 18185, 10998,\n",
      "          105,  2226,  5207,  1025, 17253, 14510,  8185,  9352,  8533,  7234,\n",
      "            3, 14950, 16778, 10527,  9868,  4274, 14206, 17222,  8345, 13551,\n",
      "         2388,  4654, 12305,  9629, 17017,  7164,   105,  5126,  8883,  1551,\n",
      "        11939,   105,  2748, 17058, 14819, 14950,  5461,  1505, 18600,  2958,\n",
      "        16674, 12929, 13437,  2916,  1869,  8705,  2050,  6813, 12362, 11101,\n",
      "        13411,  8635, 18438,  1927, 12929,  6991, 10440, 16127,   560, 17058,\n",
      "        16922,   560,  5794,  9885, 11101, 15266, 15266, 16184,  1927, 17222,\n",
      "        10791, 16622,  1334,  1454,   892, 12825, 15983,  7234,   317, 10440,\n",
      "        18556, 13595,  3425,   150, 10440,   892,  8450,  6813, 16622,  1334,\n",
      "        12373,   892, 14202,  2216, 17058, 10440, 15387, 13595,  9885,  1927,\n",
      "        17222,     4, 17266, 14032, 16702, 16447,  5897, 17908,   105, 17699,\n",
      "         5794,  2946, 12362,  1927, 16042,  5639,  3012,   105, 12929, 16382,\n",
      "         2916, 17222, 17438,  1454, 14194, 14950,   892, 15878,  3149,  6269,\n",
      "         6564, 10184, 10440,  6522, 10440, 10888,  5417, 17841,   580,  9154,\n",
      "          692, 10440, 10888, 17883,  9885,  8950,  5471, 18600,  9604, 12472,\n",
      "        16622,  1334, 12373, 12362,  3149, 11593, 17928, 10729, 11863, 18600,\n",
      "         1909, 18361, 17058, 10248,  3976,  6522,  3976, 10888,  3878,  1437,\n",
      "          580, 17222,  8901]),\n",
      " tensor([15900,  3012,  8635,  1512,  7798,   230,  4270,   724, 17058, 14675,\n",
      "         9138,  3131, 17222, 15900,  3012,  8635, 17222,  7322,   105,  3149,\n",
      "        18111,  7798,   230, 13310,  1025,  9507, 16726, 17222,  1512,  4013,\n",
      "        17222, 17035,  3031, 10729, 14880,  4088, 13317,  8635, 17222,  1857,\n",
      "          105, 12101, 17058, 10029,  7798, 13310, 13255, 16891, 16726,  7332,\n",
      "        13317, 12373,  3031, 10729, 14567, 14507, 14455,   105,  7798, 17222,\n",
      "          230,  1025, 11238,  8057, 18389, 17222, 11466, 17962, 15430, 18417,\n",
      "         7798, 11245,  1881, 17222, 15968,   230,  1025, 16729,  7234, 17222,\n",
      "        18417,  1617,   105,   580, 17222, 14152,  9770, 10729, 17222, 15430,\n",
      "        17596,   105, 18600, 17222, 11673,  9090, 16843, 14675, 17222, 17035,\n",
      "          892, 15960,  1927,  5794, 12373,   892, 18532,   692,   105, 17222,\n",
      "        17598,   105, 16560,  6463, 18389, 12287, 17222, 18099, 18600,  2958,\n",
      "        17222, 13813, 14917,   105,   724,  4270, 17058, 14675, 10888,  6919,\n",
      "        17222, 13859, 13728, 12362, 15158,   105, 17222, 11666, 11686, 12312,\n",
      "         4264,  8635,  8539,    39, 17058,  1815,  1298, 15044,  8635, 17222,\n",
      "         7742,  1334, 15430, 13813, 11589,  4116,  1159, 10729, 12438, 11658,\n",
      "        17512,   105,  1881, 17505, 18600, 17222,   230,  1025, 14827,  1927,\n",
      "        17058, 12373, 12362,  3962, 10729, 11238, 16932,  1927,  7293, 14382,\n",
      "          354,  3670, 15416, 14984, 13310, 17222,  9204,  6695, 17883,  2772,\n",
      "         5240,  4997,  7234, 17222, 16605, 12475, 12080, 11245,  3149, 11466,\n",
      "        11869,  6617, 17222, 17058, 13288,  6540,  6269, 11765, 10038, 12341,\n",
      "        17222, 17035,  9138, 12825, 17222,  6463,   105, 17222,  2537,  8804,\n",
      "         9213, 10888,  1334, 13310,  7798,  3780,  2324, 14322,  5410, 17058,\n",
      "        17681,  5428,  9584, 11238, 17073, 10729,  8621,  4088,  1114, 10729,\n",
      "        17222, 17058])]\n",
      "\n",
      "y batch: \n",
      "[tensor(1), tensor(3)]\n",
      "\n",
      "Padded X_batch:  torch.Size([2, 263]) \n",
      " tensor([[ 2946,  1927, 13292,  1281, 13491,  8469,  2946, 16737, 11041, 17222,\n",
      "         13551,  4228,   105, 17222, 13292,  2027,  7294, 11800,  8271, 10190,\n",
      "           105,  5319, 17058, 17041,  1543,  9154,  1454,  6371,  2027,  5226,\n",
      "          1454,  1701,  5417, 13289,  5034, 10729,  2483,  5319,  9868,  4300,\n",
      "          2198, 11366, 17151, 15158, 15356,  8705, 17058, 13196,  5207, 12825,\n",
      "          8732,  8705, 16778, 10527,  9868,   657,  2936,  7670,  9822,  2027,\n",
      "          5226,  5207,  2552, 16726,  7294, 12929,  6923, 16478,  2218,  2959,\n",
      "         14148, 18024,  8705,  1025, 17041, 17253, 16429, 15059, 17489,  5226,\n",
      "         13212,  1869,   105, 15249, 14950,  4041, 13279,  4371, 18185, 10998,\n",
      "           105,  2226,  5207,  1025, 17253, 14510,  8185,  9352,  8533,  7234,\n",
      "             3, 14950, 16778, 10527,  9868,  4274, 14206, 17222,  8345, 13551,\n",
      "          2388,  4654, 12305,  9629, 17017,  7164,   105,  5126,  8883,  1551,\n",
      "         11939,   105,  2748, 17058, 14819, 14950,  5461,  1505, 18600,  2958,\n",
      "         16674, 12929, 13437,  2916,  1869,  8705,  2050,  6813, 12362, 11101,\n",
      "         13411,  8635, 18438,  1927, 12929,  6991, 10440, 16127,   560, 17058,\n",
      "         16922,   560,  5794,  9885, 11101, 15266, 15266, 16184,  1927, 17222,\n",
      "         10791, 16622,  1334,  1454,   892, 12825, 15983,  7234,   317, 10440,\n",
      "         18556, 13595,  3425,   150, 10440,   892,  8450,  6813, 16622,  1334,\n",
      "         12373,   892, 14202,  2216, 17058, 10440, 15387, 13595,  9885,  1927,\n",
      "         17222,     4, 17266, 14032, 16702, 16447,  5897, 17908,   105, 17699,\n",
      "          5794,  2946, 12362,  1927, 16042,  5639,  3012,   105, 12929, 16382,\n",
      "          2916, 17222, 17438,  1454, 14194, 14950,   892, 15878,  3149,  6269,\n",
      "          6564, 10184, 10440,  6522, 10440, 10888,  5417, 17841,   580,  9154,\n",
      "           692, 10440, 10888, 17883,  9885,  8950,  5471, 18600,  9604, 12472,\n",
      "         16622,  1334, 12373, 12362,  3149, 11593, 17928, 10729, 11863, 18600,\n",
      "          1909, 18361, 17058, 10248,  3976,  6522,  3976, 10888,  3878,  1437,\n",
      "           580, 17222,  8901],\n",
      "        [15900,  3012,  8635,  1512,  7798,   230,  4270,   724, 17058, 14675,\n",
      "          9138,  3131, 17222, 15900,  3012,  8635, 17222,  7322,   105,  3149,\n",
      "         18111,  7798,   230, 13310,  1025,  9507, 16726, 17222,  1512,  4013,\n",
      "         17222, 17035,  3031, 10729, 14880,  4088, 13317,  8635, 17222,  1857,\n",
      "           105, 12101, 17058, 10029,  7798, 13310, 13255, 16891, 16726,  7332,\n",
      "         13317, 12373,  3031, 10729, 14567, 14507, 14455,   105,  7798, 17222,\n",
      "           230,  1025, 11238,  8057, 18389, 17222, 11466, 17962, 15430, 18417,\n",
      "          7798, 11245,  1881, 17222, 15968,   230,  1025, 16729,  7234, 17222,\n",
      "         18417,  1617,   105,   580, 17222, 14152,  9770, 10729, 17222, 15430,\n",
      "         17596,   105, 18600, 17222, 11673,  9090, 16843, 14675, 17222, 17035,\n",
      "           892, 15960,  1927,  5794, 12373,   892, 18532,   692,   105, 17222,\n",
      "         17598,   105, 16560,  6463, 18389, 12287, 17222, 18099, 18600,  2958,\n",
      "         17222, 13813, 14917,   105,   724,  4270, 17058, 14675, 10888,  6919,\n",
      "         17222, 13859, 13728, 12362, 15158,   105, 17222, 11666, 11686, 12312,\n",
      "          4264,  8635,  8539,    39, 17058,  1815,  1298, 15044,  8635, 17222,\n",
      "          7742,  1334, 15430, 13813, 11589,  4116,  1159, 10729, 12438, 11658,\n",
      "         17512,   105,  1881, 17505, 18600, 17222,   230,  1025, 14827,  1927,\n",
      "         17058, 12373, 12362,  3962, 10729, 11238, 16932,  1927,  7293, 14382,\n",
      "           354,  3670, 15416, 14984, 13310, 17222,  9204,  6695, 17883,  2772,\n",
      "          5240,  4997,  7234, 17222, 16605, 12475, 12080, 11245,  3149, 11466,\n",
      "         11869,  6617, 17222, 17058, 13288,  6540,  6269, 11765, 10038, 12341,\n",
      "         17222, 17035,  9138, 12825, 17222,  6463,   105, 17222,  2537,  8804,\n",
      "          9213, 10888,  1334, 13310,  7798,  3780,  2324, 14322,  5410, 17058,\n",
      "         17681,  5428,  9584, 11238, 17073, 10729,  8621,  4088,  1114, 10729,\n",
      "         17222, 17058,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]) \n",
      "\n",
      "\n",
      "Embeddings:  torch.Size([2, 263, 5]) \n",
      " tensor([[[ 1.4999e-01,  8.8442e-01,  6.5550e-01, -2.7721e-01,  8.1018e-01],\n",
      "         [ 1.0835e+00, -7.9928e-01,  6.3749e-01,  3.8347e-01,  1.3543e+00],\n",
      "         [-4.5050e-02, -1.8984e-02,  1.9920e-01, -1.1240e-01,  1.0512e-01],\n",
      "         ...,\n",
      "         [ 8.5309e-01, -1.0771e+00, -7.9528e-01,  1.3609e-01,  2.6316e-01],\n",
      "         [ 3.1157e-01, -1.5996e-03, -1.3382e+00,  6.8702e-01, -3.5672e-01],\n",
      "         [-1.5421e+00,  8.8431e-02, -6.9981e-01,  1.2134e+00, -7.6884e-02]],\n",
      "\n",
      "        [[-1.3140e+00,  5.4180e-01, -3.1592e-01, -1.0534e+00,  1.1482e+00],\n",
      "         [ 5.0183e-02,  3.6072e-01,  1.3381e+00,  4.8476e-02,  2.9406e-01],\n",
      "         [-5.4472e-01,  2.5320e+00,  1.0276e+00,  2.3152e-01, -1.0761e+00],\n",
      "         ...,\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01],\n",
      "         [-6.5398e-01, -1.6095e+00, -1.0017e-01, -6.0919e-01, -9.7977e-01]]]) \n",
      "\n",
      "\n",
      "Embeddings transposed for CNN:  torch.Size([2, 5, 263]) \n",
      " tensor([[[ 1.4999e-01,  1.0835e+00, -4.5050e-02,  ...,  8.5309e-01,\n",
      "           3.1157e-01, -1.5421e+00],\n",
      "         [ 8.8442e-01, -7.9928e-01, -1.8984e-02,  ..., -1.0771e+00,\n",
      "          -1.5996e-03,  8.8431e-02],\n",
      "         [ 6.5550e-01,  6.3749e-01,  1.9920e-01,  ..., -7.9528e-01,\n",
      "          -1.3382e+00, -6.9981e-01],\n",
      "         [-2.7721e-01,  3.8347e-01, -1.1240e-01,  ...,  1.3609e-01,\n",
      "           6.8702e-01,  1.2134e+00],\n",
      "         [ 8.1018e-01,  1.3543e+00,  1.0512e-01,  ...,  2.6316e-01,\n",
      "          -3.5672e-01, -7.6884e-02]],\n",
      "\n",
      "        [[-1.3140e+00,  5.0183e-02, -5.4472e-01,  ..., -6.5398e-01,\n",
      "          -6.5398e-01, -6.5398e-01],\n",
      "         [ 5.4180e-01,  3.6072e-01,  2.5320e+00,  ..., -1.6095e+00,\n",
      "          -1.6095e+00, -1.6095e+00],\n",
      "         [-3.1592e-01,  1.3381e+00,  1.0276e+00,  ..., -1.0017e-01,\n",
      "          -1.0017e-01, -1.0017e-01],\n",
      "         [-1.0534e+00,  4.8476e-02,  2.3152e-01,  ..., -6.0919e-01,\n",
      "          -6.0919e-01, -6.0919e-01],\n",
      "         [ 1.1482e+00,  2.9406e-01, -1.0761e+00,  ..., -9.7977e-01,\n",
      "          -9.7977e-01, -9.7977e-01]]]) \n",
      "\n",
      "\n",
      "CNN output:  torch.Size([2, 10, 263]) \n",
      " tensor([[[0.0000, 0.1087, 0.2263,  ..., 0.0165, 0.0000, 0.1003],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0375],\n",
      "         [0.0000, 0.3335, 0.1460,  ..., 0.0206, 0.1182, 0.0000],\n",
      "         ...,\n",
      "         [0.2510, 0.0000, 0.0202,  ..., 0.2476, 0.0097, 0.2448],\n",
      "         [0.2172, 0.0653, 0.0000,  ..., 0.0000, 0.0000, 0.0711],\n",
      "         [0.1570, 0.0274, 0.0195,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.2714, 0.3987, 0.3012],\n",
      "         [0.0000, 0.0000, 0.0299,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1735, 0.0898,  ..., 0.3579, 0.2013, 0.2866],\n",
      "         ...,\n",
      "         [0.0637, 0.0000, 0.0505,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.2399,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0489,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "\n",
      "Maxpool output:  torch.Size([2, 10, 87]) \n",
      " tensor([[[0.2263, 0.1815, 0.5270,  ..., 0.2957, 0.2372, 0.0585],\n",
      "         [0.0000, 0.0000, 0.0816,  ..., 0.0941, 0.0000, 0.0316],\n",
      "         [0.3335, 0.0542, 0.4417,  ..., 0.2257, 0.1887, 0.0331],\n",
      "         ...,\n",
      "         [0.2510, 0.4570, 0.2778,  ..., 0.2693, 0.5828, 0.4287],\n",
      "         [0.2172, 0.3304, 0.0850,  ..., 0.2591, 0.4840, 0.3175],\n",
      "         [0.1570, 0.1151, 0.0000,  ..., 0.0000, 0.0218, 0.0435]],\n",
      "\n",
      "        [[0.0000, 0.3450, 0.2123,  ..., 0.2714, 0.2714, 0.2714],\n",
      "         [0.0299, 0.1910, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1735, 0.2934, 0.0190,  ..., 0.3579, 0.3579, 0.3579],\n",
      "         ...,\n",
      "         [0.0637, 0.6828, 0.4497,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2399, 0.5823, 0.2681,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0489, 0.2732, 0.3484,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "\n",
      "Linear input:  torch.Size([2, 10]) \n",
      " tensor([[0.7729, 0.3767, 0.6558, 0.4796, 0.4435, 0.7880, 0.7517, 0.7764, 0.8082,\n",
      "         0.4031],\n",
      "        [0.7343, 0.3374, 0.6151, 0.4062, 0.3713, 0.6974, 0.7576, 0.6828, 0.6293,\n",
      "         0.4415]])\n",
      "\n",
      "Linear Output:\n",
      " tensor([[-0.4880,  0.7419, -0.5965,  0.0311, -0.0608],\n",
      "        [-0.4573,  0.7005, -0.5830,  0.0681, -0.1317]])\n",
      "\n",
      "Log Softmax:\n",
      " tensor([[-2.1437, -0.9139, -2.2523, -1.6246, -1.7166],\n",
      "        [-2.0969, -0.9391, -2.2226, -1.5715, -1.7712]])\n",
      "\n",
      "Y Output Tag: \n",
      " tensor([1, 1])\n",
      "\n",
      "Actual Output: \n",
      "[tensor(1), tensor(3)]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in sample_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i) for i in x_batch]\n",
    "        y_batch = [torch.tensor(i) for i in y_batch]\n",
    "        \n",
    "        \n",
    "        print(\"X batch: \")\n",
    "        pprint(x_batch)\n",
    "        print(\"\\ny batch: \")\n",
    "        pprint(y_batch)\n",
    "        \n",
    "        y_out = cnn_model_sample(x_batch)\n",
    "                        \n",
    "        _, y_out_tag = torch.max(y_out, dim = 1)\n",
    "        print(\"\\nY Output Tag: \\n\", y_out_tag)\n",
    "        \n",
    "        print(\"\\nActual Output: \")\n",
    "        print(y_batch)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acutal Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 512\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestData(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=1, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, target_size):\n",
    "        super(ModelCNN, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=128, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=10, kernel_size=3, stride=1, padding = 1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.linear = nn.Linear(in_features = 10, out_features=target_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_batch):        \n",
    "        padded_batch = pad_sequence(x_batch, batch_first=True)\n",
    "        embeds = self.word_embeddings(padded_batch)\n",
    "        embeds_t = embeds.transpose(1, 2)\n",
    "        \n",
    "        cnn1 = torch.relu(self.conv1(embeds_t))\n",
    "        cnn2 = torch.relu(self.conv2(cnn1))\n",
    "        maxpool1 = self.maxpool(cnn2)\n",
    "        linear_in, _ = torch.max(maxpool1, dim = 2)\n",
    "        \n",
    "        linear_out = self.linear(linear_in)\n",
    "        \n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCNN(\n",
      "  (word_embeddings): Embedding(18636, 512)\n",
      "  (conv1): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(128, 10, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_model = ModelCNN(embedding_size=EMBEDDING_SIZE, vocab_size=len(word2idx), target_size=len(tag2idx))\n",
    "\n",
    "cnn_model.to(device)\n",
    "print(cnn_model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer =  optim.Adam(cnn_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 1.40272 | Acc: 0.0\n",
      "Epoch 002: | Loss: 0.79136 | Acc: 100.0\n",
      "Epoch 003: | Loss: 0.38017 | Acc: 100.0\n",
      "Epoch 004: | Loss: 0.16631 | Acc: 100.0\n",
      "Epoch 005: | Loss: 0.07012 | Acc: 100.0\n",
      "Epoch 006: | Loss: 0.03393 | Acc: 100.0\n",
      "Epoch 007: | Loss: 0.01774 | Acc: 100.0\n",
      "Epoch 008: | Loss: 0.01027 | Acc: 100.0\n",
      "Epoch 009: | Loss: 0.00709 | Acc: 100.0\n",
      "Epoch 010: | Loss: 0.00522 | Acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "cnn_model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = cnn_model(x_batch)        \n",
    "        \n",
    "        loss = criterion(y_pred.squeeze(0), y_batch)\n",
    "        acc = multi_acc(y_pred.squeeze(0), y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = map(list, zip(*batch))\n",
    "        x_batch = [torch.tensor(i).to(device) for i in x_batch]\n",
    "        y_batch = torch.tensor(y_batch).long().to(device)\n",
    "        \n",
    "        y_pred = cnn_model(x_batch)\n",
    "        _, y_pred_tag = torch.max(y_pred, dim = 1)\n",
    "\n",
    "        y_out_tags_list.append(y_pred_tag.squeeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87   2   6   9   9]\n",
      " [  5 130   5   1  12]\n",
      " [ 10   5  96  12   5]\n",
      " [ 18   1  13 123   5]\n",
      " [  8   4   7   6  89]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_tags_list = [a.squeeze().tolist() for a in y_out_tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       113\n",
      "           1       0.92      0.85      0.88       153\n",
      "           2       0.76      0.75      0.75       128\n",
      "           3       0.81      0.77      0.79       160\n",
      "           4       0.74      0.78      0.76       114\n",
      "\n",
      "    accuracy                           0.79       668\n",
      "   macro avg       0.78      0.78      0.78       668\n",
      "weighted avg       0.79      0.79      0.79       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_out_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                                                                            : Sentiment      \n",
      "\n",
      "stam spices up man utd encounter ac milan defender stam says manchester united know they made a mistake by selling him in the sides meet at old trafford in the champions league game on wednesday and the year old s dutchman s presence is sure to add spice to the fixture united made a mistake in selling me stam told uefa s champions magazine i was settled at manchester united but they wanted to sell me if a club want to sell you there is nothing you can do you can be sold like cattle sir alex ferguson surprised the football world and stam by selling the dutchman to lazio for m in august the decision came shortly after stam claimed in his autobiography that ferguson had tapped him up when he was at psv eindhoven but ferguson insisted he sold the defender because the transfer fee was too good to refuse for a player past his prime the affair still with the dutchman i was settled at manchester united i had even just ordered a new kitchen but they wanted to sell me he said in what other industry can a good employee be ushered out the door against their wishes of course you can refuse to go but then the club have the power to put you on the bench i don t agree that players control the game there have been opportunities to confront them in the newspapers but i have turned them down what s the point wednesday s game at old trafford will provide an intriguing confrontation between united s young attackers wayne rooney and cristiano ronaldo and milan s veteran defence of stam paolo maldini and alessandro costacurta stam says rooney s teenage stardom is in stark contract to his own start in the game we can t all be wayne at his age i was training to be an and thought my chance of becoming a professional footballer had gone he said starting late can be a good thing some kids who start early get bored i had my youth having fun drinking beers up milk it sounds strange but it s a tradition where i grew up in and i had done all the things i wanted to do:     1\n",
      "\n",
      "vibe awards back despite violence the us vibe awards will be held again next year despite a stabbing which happened during the ceremony vibe magazine president gibbs said the attack earlier this month in santa monica was he said not holding the awards would be counter to the work the magazine has done to promote hip hop music rapper young buck has been charged after allegedly stabbing a man who hit dr dre as he was about to receive a lifetime achievement award the rapper whose real name is david brown is due in court on december after being arrested on one charge of attempted murder and a second charge of assault with a deadly weapon the performer is one of the members of cent s g unit group which is signed to dr dre s record label the man who was stabbed jimmy james johnson suffered a collapsed lung and is in a stable condition at a los angeles hospital mr johnson allegedly approached dr dre who was at a table in front of the stage and appeared to ask for an before punching him during the ensuing which involved many of the strong crowd mr johnson was stabbed as he was being dragged away by security staff:     4\n",
      "\n",
      "sfa awaits report over mikoliunas the scottish football association is awaiting referee hugh dallas s report before acting against hearts winger mikoliunas mikoliunas linesman andy davis who had advised dallas to award rangers an injury time penalty in hearts s defeat at tynecastle he was sent off for violent conduct in the th minute but we don t know if he did something else after the whistle we don t know how many red cards he was shown said an sfa statement hearts could also face action after three fans were arrested for throwing coins on the pitch rangers striker dad prso was also sent off during the same incident when he received a second yellow card for the ball away from craig gordon and leaving the hearts keeper on the ground the sfa said once the referee s report comes in then we ll immediately look at things we don t normally get the reports until a couple of days after the game but we re well aware of what happened here prso was sent off for two and that will just be a one match suspension the sfa is certain to come down hard on mikoliunas after southampton s david prutton was banned for games on wednesday by the english fa for shoving referee alan wiley hearts boss john robertson said mikoliunas has thrown his chest against the assistant referee s chest and got a red card for it the officials have got to take into account the fact he s a young lad but people have got to take into account why he was incensed why were hearts fans incensed why did nobody from the rangers bench claim for a penalty kick rangers boss alex mcleish accepted referee dallas had no option but to send prso off mcleish said i m glad to see the spirit of the players fighting to the very end literally with dado trying to get the ball back from craig gordon but it was over and i don t think hugh had any option:     1\n",
      "\n",
      "greek duo cleared in doping case sprinters kostas kenteris and katerina thanou have been cleared of doping offences by an independent tribunal the duo had been provisionally suspended by the iaaf for allegedly missing three drugs tests including one on the eve of the athens olympics but the greek athletics federation tribunal has overturned the bans a decision which the iaaf can now contest at the court of arbitration for sport the pair s former coach christos tzekos has been banned for four years kenteris and thanou had been charged with avoiding drug tests in tel aviv chicago and athens and failing to notify anti doping officials of their whereabouts before the olympics they withdrew from the olympics after missing a drugs test at the olympic village on august the pair then spent four days in a hospital claiming they had been injured in a motorcycle crash it was the international olympic committee s demand that the iaaf investigate the affair that led to the hearing of the greek tribunal the head of that tribunal kostas panagopoulos said it had not been proven that the athletes refused to take the test in athens the charge cannot be substantiated he said in no way was he kenteris informed to appear for a doping test the same goes for thanou kenteris s lawyer gregory ioannidis said the decision means mr kenteris has been exonerated of highly damaging and unfounded charges which have been extremely harmful for his career he has consistently maintained his innocence and this was substantiated by further evidence we were able to submit to the tribunal following its deliberations in january this evidence shows mr kenteris was never asked to submit to a test by the international olympic committee so he could not possibly have been guilty of deliberately avoiding one it shows he has no case to answer mr kenteris should now be given the opportunity he deserves to rebuild his career in the full knowledge that there is no stain on his character he has suffered greatly throughout this ordeal that has exposed both himself and his family to enormous pressures but the iaaf said it was very surprised by the verdict spokesman nick davies said we note the decision of the greek authorities with interest our doping review board will now consider the english version of the decision:     4\n",
      "\n",
      "malaysia lifts islamic bank limit malaysia s central bank is to relax restrictions on foreign ownership to encourage islamic banking banks in malaysia will now be able to sell up to of their islamic banking units while the limit on other kinds of bank remains at malaysia s third biggest lender is already for a foreign partner for its new islamic banking unit the firm told reuters the moves put malaysia ahead of a deadline to open up the sector the country s deal to join the world trade organisation set that year as a deadline for liberalisation of islamic banking also on tuesday the central bank released growth figures showing malaysia s economy expanded in but growth slowed sharply in the fourth quarter to and the central bank said it expected expansion in malaysia changed the law to allow islamic banking in it has granted licences to three middle eastern groups which along with local players mean there are eight fully operational islamic banking groups in the country islamic banks offer services which permit modern banking principles while sticking to islamic law s ban on the payment of interest most of the which make up half the country s population are muslims:     3\n",
      "\n",
      "looks and music to drive mobiles mobile phones are still enjoying a boom time in sales according to research from technology analysts gartner more than million mobiles were sold last year globally said the report the highest total sold to date the figure was more than in and surpassed even the most optimistic predictions gartner said good design and the look of a mobile as well as new services such as music downloads could go some way to pushing up sales in said analysts although people were still looking for better replacement phones there was evidence according to gartner that some markets were seeing a slow down in replacement sales all the markets grew apart from japan which shows that replacement sales are continuing in western europe mobile analyst carolina milanesi told the bbc news website japan is where north america and western european markets can be in a couple of years time they already have tv music ringtones cameras and all that we can think of on mobiles so people have stopped buying replacement phones but there could be a slight slowdown in sales in european and us markets too according to gartner as people wait to see what comes next in mobile technology this means mobile companies have to think carefully about what they are offering in new models so that people see a compelling reason to upgrade said gartner third generation mobiles g with the ability to handle large amounts of data transfer like video could drive people into upgrading their phones but ms milanesi said it was difficult to say how quickly that would happen at the end of the day people have cameras and colour screens on mobiles and for the majority of people out there who don t really care about technology the speed of data to a phone is not critical nor would the rush to produce two or three megapixel camera phones be a reason for mobile owners to upgrade on its own the majority of camera phone models are not at the stage where they can compete with digital cameras which also have flashes and zooms more likely to drive sales in would be the attention to design and aesthetics as well as music services the motorola razr v phone was typical of the attention to design that would be more commonplace in she added this was not a women s thing she said but a desire from men and women to have a gadget that is a form of self expression too it was not just about how the phone functioned but about what it said about its owner western europe has always been a market which is quite attentive to design said ms milanesi people are after something that is nice looking and together with that there is the entertainment side this year music will have a part to play in this the market for full track music downloads was worth just million million in but is set to be worth billion million by according to research sony ericsson just released its walkman branded mobile phone the w which combines a digital music player with up to hours battery life and a two megapixel camera in july last year motorola and apple announced a version of itunes online music downloading service would be released which would be compatible with motorola mobile phones apple said the new itunes music player would become motorola s standard music application for its music phones but the challenge will be balancing storage capacity with battery life if mobile music hopes to compete with digital music players like the ipod ms milanesi said more models would likely be released in the coming year with hard drives but they would be more likely to compete with the smaller capacity music players that have around four gigabyte storage capacity which would not put too much strain on battery life:     0\n",
      "\n",
      "saudi ncci s shares soar shares in saudi arabia s national company for cooperative insurance ncci soared on their first day of trading in riyadh they were trading above the offer price on monday changing hands at riyals after topping early in the day demand for the insurer s debut shares was strong times what was on sale the listing was part of the country s plans to open up its insurance market and boost demand in the sector deregulation is expected to boost demand for accident and damage cover previously only ncci has been legally allowed to offer insurance products within saudi arabia however the authorities have turned a blind eye to the many other firms selling insurance saudi arabia now wants a fully insurance industry and is introducing legislation that will clamp down on unauthorised companies policy makers also want to make having insurance more of a requirement but first have to take steps to boost public confidence in the system analysts said as a result ncci is being developed as the industry s flagship firm publicly listed with audited accounts saudi arabia sold million ncci shares or about of the company s total capital last month more than applicants got shares each for riyals apiece:     0\n",
      "\n",
      "fao warns on impact of subsidies billions of farmers livelihoods are at risk from falling commodity prices and the un s food agriculture organisation has warned trade barriers and subsidies severely distort the market the fao report on the state of agricultural commodity markets said as a result the billion people in the developing world who rely on farming face food insecurity the most endangered are those who live in the least developed countries the fao report said that support for farmers in industrialised nations was equivalent to times the amount provided as aid for agricultural development in poor countries the fao has urged the world trade organisation to swiftly conclude negotiations to liberalise trade easing developing countries access to the world market it also criticised the high tariffs imposed by both developed and developing nations it recommends that developing countries reduce their own tariffs to encourage trade and take advantage of market liberalisation according to the organisation subsidies and high tariffs have a strong impact on the trade of products such as cotton and rice global exports of these products are mainly in the hands of the european union and the us who thanks to subsidies sell them at very low prices in fact almost wealthy nations spend more than bn bn bn euros in agricultural subsidies the market situation has divided developing nations in two groups the fao said the first group have a reasonably diverse range of agricultural products while in the second group agriculture lies largely in the hands of small scale producers for developing countries more than of their export incomes come from the sale of just one product these countries are mainly situated in sub saharan africa latin america and the caribbean:     3\n",
      "\n",
      "venezuela identifies idle farms venezuelan authorities have identified more than farms including large estates as idle as it continues with its controversial land reform policy under a land law the government can tax or seize unused farm sites a further farms are yet to be inspected the state s national land institute has told associated press vice president jose rangel has said farmers and with their titles in order and their lands productive have nothing to fear critics of the land reform policy claim president hugo chavez is trying to enforce a communist style economic programme that ignores property rights and will damage the country land owners claim the national land institute has made mistakes in lands as public or private but the government venezuela s largest land owner say they are proceeding cautiously to prevent conflicts in a statement mr rangel said the land reform is not against the constitution which permits private property while stressing the efforts are to social and economically years of inequality in the country one property in conflict with the government is the el charcote cattle ranch run by agroflora a subsidiary of the uk food group vestey agriculture minister marquez told reuters news agency the site s documents do not guarantee that this is a private land administrators of the ranch however have complained that pro chavez have taken over of the property in the last four years and the uk government has asked venezuelan authorities to resolve the conflict you should ask the company when they are going to put their papers in order and hand over the land that is not theirs said mr marquez:     0\n",
      "\n",
      "mild winter drives us oil down us oil prices have fallen by driven down by forecasts of a mild winter in the populated northeast light crude oil futures fell to a barrel on the new york exchange and have now lost in five days nonetheless us crude is still more expensive than at the beginning of boosted by growing demand and bottlenecks at refineries traders ignored the possible effects of asia s tidal waves on global supplies instead the focus is now on us consumption which is heavily influenced in the short term by the weather with the revised milder temperatures i m more inclined to think we ll push lower and test the range said john brady of abn amro the market definitely feels to be on the defensive statistics released last week showed that stockpiles of oil products in the us had risen an indication that severe supply disruptions may not arise this winter barring any serious incident oil prices have broken records in topping a barrel at one point driven up by a welter of worries about unrest in iraq and saudi arabia rising demand and supply bottlenecks london s international petroleum exchange remained closed for the christmas holiday:     1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{:80}: {:15}\\n'.format(\"Word\", \"Sentiment\"))\n",
    "for sentence, tag in zip(X_test[:10], y_out_tags_list[:10]):\n",
    "    s = \" \".join([idx2word[w] for w in sentence])\n",
    "    print('{:80}: {:5}\\n'.format(s, tag))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
